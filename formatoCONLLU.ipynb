{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f5f652",
   "metadata": {},
   "source": [
    "# Aplicar preprocesado y formatear texto\n",
    "En este notebook vamos a aplicar el preprocesado que hemos estudiado en el notebook anterior al corpus que tenemos. Tras ello, vamos a pasar el texto a formato conllu, que es lo que el modelo que usamos para resolver las referencias usa como entrada. Esto lo hemos dividido así porque nos ahorramos guardar el dataset etiquetado, ya lo guardamos todo en formato conllu.  \n",
    "Para el preprocesado que le vamos a aplicar, vamos a guardarlo en un archivo .py para mejorar la legibilidad y paralelizar el código para que lo haga un poco más rápido. Además, esas funciones ya las definimos en el notebook de preprocesar, por lo que simplemente copiamos aquellas funciones que usamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6b639",
   "metadata": {},
   "source": [
    "# 1 Aplicar preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000aa61",
   "metadata": {},
   "source": [
    "## 1.1 Imports\n",
    "Vamos a poner todos los imports que necesitamos para aplicar el preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0470616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import preprocesar\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a94bc6",
   "metadata": {},
   "source": [
    "## 1.2 Funciones auxiliares\n",
    "Ahora vamos a definir nuestra función para preprocesar el texto y todas sus sub-funciones. Recordemos que primero vamos a pasarle nuestro tokenizador personalizado y despues el modelo stanza para sacar las part-of-speech-tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0587e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tags(docs: list = []):\n",
    "    for sentence in docs.sentences:\n",
    "        for token in sentence.words:\n",
    "            print(token.text, token.pos)\n",
    "        print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7ac2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CulturaX.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "  \n",
    "# Cogemos un subset\n",
    "dt = data[:500]\n",
    "# Le pasamos solo los textos\n",
    "texts = [d['text'] for d in dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea5ff15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960db1ac426b479cb4cd0543b7bff40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocesando:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, imperative_meta = preprocesar.preprocesar_paralelo(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12c4bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gobierno NOUN\n",
      "confía VERB\n",
      "en ADP\n",
      "que SCONJ\n",
      "corte NOUN\n",
      "constitucional ADJ\n",
      "dé VERB\n",
      "vía NOUN\n",
      "libre ADJ\n",
      "a ADP\n",
      "el DET\n",
      "mecanismo NOUN\n",
      "fast PROPN\n",
      "track PROPN\n",
      "- PUNCT\n",
      "eje21 ADJ\n",
      "gobierno NOUN\n",
      "confía VERB\n",
      "en ADP\n",
      "que SCONJ\n",
      "corte NOUN\n",
      "constitucional ADJ\n",
      "dé VERB\n",
      "vía NOUN\n",
      "libre ADJ\n",
      "a ADP\n",
      "el DET\n",
      "mecanismo NOUN\n",
      "fast PROPN\n",
      "track PROPN\n",
      "bogotá PROPN\n",
      ", PUNCT\n",
      "04 NUM\n",
      "de ADP\n",
      "diciembre PROPN\n",
      "_ PUNCT\n",
      "ram_ NOUN\n",
      "así ADV\n",
      "lo PRON\n",
      "confirmó VERB\n",
      "este DET\n",
      "sábado NOUN\n",
      "el DET\n",
      "ministro NOUN\n",
      "de ADP\n",
      "el DET\n",
      "interior NOUN\n",
      "juan PROPN\n",
      "fernando PROPN\n",
      "cristo PROPN\n",
      ", PUNCT\n",
      "quien PRON\n",
      "señaló VERB\n",
      "que SCONJ\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "el DET\n",
      "gobierno NOUN\n",
      "emprenderá VERB\n",
      "el DET\n",
      "camino NOUN\n",
      "de ADP\n",
      "implementación NOUN\n",
      "de ADP\n",
      "el DET\n",
      "nuevo ADJ\n",
      "acuerdo NOUN\n",
      "de ADP\n",
      "paz NOUN\n",
      "que PRON\n",
      "decida VERB\n",
      "la DET\n",
      "corte NOUN\n",
      "constitucional ADJ\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "confía VERB\n",
      "en ADP\n",
      "que SCONJ\n",
      "la DET\n",
      "decisión NOUN\n",
      "sobre ADP\n",
      "la DET\n",
      "vía NOUN\n",
      "rápida ADJ\n",
      "para ADP\n",
      "la DET\n",
      "implementación NOUN\n",
      "de ADP\n",
      "las DET\n",
      "leyes NOUN\n",
      "de ADP\n",
      "paz NOUN\n",
      "se PRON\n",
      "tome VERB\n",
      "antes ADV\n",
      "de ADP\n",
      "la DET\n",
      "vacancia NOUN\n",
      "judicial ADJ\n",
      "y CCONJ\n",
      "el DET\n",
      "fin NOUN\n",
      "de ADP\n",
      "esta DET\n",
      "legislatura NOUN\n",
      "en ADP\n",
      "el DET\n",
      "congreso NOUN\n",
      ", PUNCT\n",
      "\" PUNCT\n",
      "tenemos VERB\n",
      "la DET\n",
      "fe NOUN\n",
      "de ADP\n",
      "que SCONJ\n",
      "va VERB\n",
      "a ADP\n",
      "dar VERB\n",
      "salidas NOUN\n",
      "que PRON\n",
      "garanticen VERB\n",
      "implementación NOUN\n",
      "rápida ADJ\n",
      "de ADP\n",
      "los DET\n",
      "acuerdos NOUN\n",
      "\" PUNCT\n",
      ". PUNCT\n",
      "\n",
      "--------------------\n",
      "maquina NOUN\n",
      "trituradora ADJ\n",
      "de ADP\n",
      "mineral NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      "en ADP\n",
      "malasia NOUN\n",
      "para ADP\n",
      "la DET\n",
      "minería NOUN\n",
      "máquinas NOUN\n",
      "para ADP\n",
      "la DET\n",
      "venta NOUN\n",
      "malasia ADJ\n",
      "llave NOUN\n",
      "en ADP\n",
      "mano NOUN\n",
      "equipos NOUN\n",
      "de ADP\n",
      "la DET\n",
      "mineria NOUN\n",
      "de ADP\n",
      "roca NOUN\n",
      "equipo NOUN\n",
      "en ADP\n",
      ". PUNCT\n",
      "cianuro NOUN\n",
      "de ADP\n",
      "sodio NOUN\n",
      "para ADP\n",
      "la DET\n",
      "minería NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      "para ADP\n",
      "la DET\n",
      "venta NOUN\n",
      ". PUNCT\n",
      "\n",
      "ahora ADV\n",
      "contamos VERB\n",
      "con ADP\n",
      "cianuro NOUN\n",
      "de ADP\n",
      "sodio NOUN\n",
      "en ADP\n",
      "grandes ADJ\n",
      "cantidades NOUN\n",
      "y CCONJ\n",
      "90 NUM\n",
      "% SYM\n",
      "de ADP\n",
      "nuestro DET\n",
      "producto NOUN\n",
      "es AUX\n",
      "para ADP\n",
      "la DET\n",
      "exportación NOUN\n",
      ". PUNCT\n",
      "\n",
      "roca NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      "de ADP\n",
      "trituración NOUN\n",
      "de ADP\n",
      "maquinaria NOUN\n",
      "de ADP\n",
      "obras NOUN\n",
      ". PUNCT\n",
      "\n",
      "las DET\n",
      "máquinas NOUN\n",
      "utilizadas ADJ\n",
      "para ADP\n",
      "la DET\n",
      "trituración NOUN\n",
      "de ADP\n",
      ", PUNCT\n",
      "de ADP\n",
      "oro NOUN\n",
      "en ADP\n",
      "china NOUN\n",
      ", PUNCT\n",
      ", PUNCT\n",
      "mineral NOUN\n",
      "de ADP\n",
      "hierro NOUN\n",
      ", PUNCT\n",
      "trituradora NOUN\n",
      "de ADP\n",
      "mineral NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      ", PUNCT\n",
      ". PUNCT\n",
      "\n",
      "trituradora NOUN\n",
      "de ADP\n",
      "mineral NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      "para ADP\n",
      "la DET\n",
      "venta NOUN\n",
      ". PUNCT\n",
      "\n",
      "molinos NOUN\n",
      "para ADP\n",
      "triturar VERB\n",
      "mineral NOUN\n",
      "de ADP\n",
      "oro NOUN\n",
      "trituradora ADJ\n",
      "de ADP\n",
      "cono NOUN\n",
      ". PUNCT\n",
      "\n",
      "molinos NOUN\n",
      "para ADP\n",
      "agregados NOUN\n",
      "para ADP\n",
      "concreto NOUN\n",
      "en ADP\n",
      "nigeria NOUN\n",
      ". PUNCT\n",
      "obtener VERB\n",
      "precio NOUN\n",
      ". PUNCT\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las etiquetas\n",
    "for d in doc[:2]:   \n",
    "    print_tags(d)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1354cf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fc4f2e",
   "metadata": {},
   "source": [
    "# 2 Pasar a formato conllu\n",
    "Ahora vamos a pasar los datos que hemos sacado antes a formato conllu. Para ello vamos a definir unas funciones auxiliares que nos ayudarán. Vamos a mencionar cómo se construye el formato conllu:\n",
    "1. Se incluyen líneas comentadas con el documento al que pertenece la frase, un identificador que nos diga que frase es dentro del documento y la frase original antes del tokenizado. <br><br>\n",
    "2. Una linea para cada palabra que constará de 10 columnas:\n",
    " - **ID**: Índice del token. Su posición dentro de la oración.\n",
    " - **FORM**: Forma de la palabra. Palabra que aparece tal cual en el texto original.\n",
    " - **LEMMA**: Forma base de la palabra.\n",
    " - **UPOS**: Categoría gramatical universal de la palabra.\n",
    " - **XPOS**: Etiqueta gramatical específica del idioma.\n",
    " - **FEATS**: Lista de rasgos morfológicos (género, número, tiempo, persona).\n",
    " - **HEAD**: El ID de la palabra de la que depende.\n",
    " - **DEPREL**: El tipo de relación con el HEAD.\n",
    " - **DEPS**: Grafo de dependencias mejorado.\n",
    " - **MISC**: Cualquier otra información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b93864",
   "metadata": {},
   "source": [
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6651e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70dcd7d",
   "metadata": {},
   "source": [
    "## 2.2 Funciones auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb316b",
   "metadata": {},
   "source": [
    "**stanza_doc_to_conllu**\n",
    "\n",
    "Entrada: \n",
    "- Texto tokenizado por stanza\n",
    "- Lista de palabras a las que hay que cambiarles algún campo\n",
    "\n",
    "Salida: Texto en formato conllu\n",
    "\n",
    "Recorreras cada oración analizada por stanza y escribirás los encabezados que identifican cada frase. Después se cambiarán de forma manual los lemmas y upos de las palabras que coincidieron con algún patrón de la lista de excepciones para que no se pierda el significado.\n",
    "\n",
    "Una vez hecho esto, el código recolectará los atributos del análisis que stanza hizo previamente y los dispondrá en el formato conllu final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aea7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_doc_to_conllu(doc, imperative_meta) -> str:\n",
    "    lines = []\n",
    "    sent_id = 1\n",
    "\n",
    "    for sent in doc.sentences:\n",
    "        # Identificadores de cada frase\n",
    "        lines.append(f\"# sent_id = {sent_id}\")\n",
    "        lines.append(f\"# text = {sent.text}\")\n",
    "\n",
    "        for word in sent.words:\n",
    "            lemma = word.lemma\n",
    "            upos = word.upos\n",
    "\n",
    "            # Corrección manual del lema si viene de whitelist\n",
    "            for meta in imperative_meta:\n",
    "                if word.text.lower() == meta[\"base\"]:\n",
    "                    lemma = meta[\"lemma\"]\n",
    "                    upos = meta[\"upos\"]\n",
    "\n",
    "            # Extracción de los atributos de las palabras\n",
    "            feats = word.feats if word.feats else \"_\"\n",
    "\n",
    "            misc = []\n",
    "            if word.start_char is not None and word.end_char is not None:\n",
    "                misc.append(f\"CharOffset={word.start_char}:{word.end_char}\")\n",
    "            misc = \"|\".join(misc) if misc else \"_\"\n",
    "\n",
    "            # Construcción del conllu final\n",
    "            lines.append(\"\\t\".join([\n",
    "                str(word.id),        # ID\n",
    "                word.text,           # FORM\n",
    "                lemma or \"_\",         # LEMMA (corregido)\n",
    "                upos or \"_\",          # UPOS\n",
    "                word.xpos or \"_\",     # XPOS\n",
    "                feats,                # FEATS\n",
    "                str(word.head),       # HEAD\n",
    "                word.deprel or \"_\",   # DEPREL\n",
    "                \"_\",                  # DEPS\n",
    "                misc                  # MISC\n",
    "            ]))\n",
    "\n",
    "        lines.append(\"\")\n",
    "        sent_id += 1\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d99e7",
   "metadata": {},
   "source": [
    "FUNCIÓN PRUNCIPAL: TEXTO(S) → CoNLL-U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef425120",
   "metadata": {},
   "source": [
    "**texts_to_conllu**\n",
    "\n",
    "Esta celda es la función principal que irá llamando a las funciones de las celdas anteriores.\n",
    "\n",
    " 1º- Sustituye los verbos con clíticos por palabras separadas. Ej: dímelo -> di + me + lo\n",
    "\n",
    " 2º- Tokenizarás cada palabra con stanza.pipeline\n",
    "\n",
    " 3º- Construye la salida del preprocesado en un texto formato conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f429e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_conllu(docs, imperative_metas):\n",
    "    conllu_list = []; i = 1\n",
    "    \n",
    "    # Usar tqdm en el zip con descripción personalizada\n",
    "    for doc, imperative_meta in tqdm(zip(docs, imperative_metas), \n",
    "                                                    total=len(docs), \n",
    "                                                    desc=\"Procesando documentos\"):\n",
    "        # Dar formato conllu a los tokens de la frase\n",
    "        conllu = stanza_doc_to_conllu(doc, imperative_meta)\n",
    "        \n",
    "        # Separación entre frases\n",
    "        conllu_list.append(f\"# newdoc id = doc_{i}\")\n",
    "        conllu_list.append(conllu)\n",
    "        i+=1\n",
    "    \n",
    "    return \"\\n\".join(conllu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738fb5e0",
   "metadata": {},
   "source": [
    "## 2.3 Sacar conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9142bb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2454274299147398144e6bf445ca459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando documentos:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conllu_output = texts_to_conllu(doc, imperative_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb6613",
   "metadata": {},
   "source": [
    "Vamos a mostrar un poco la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbc6d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26427677\n",
      "# newdoc id = doc_1\n",
      "# sent_id = 1\n",
      "# text = gobierno confía en que corte constitucional dé vía libre al mecanismo fast track - eje21\n",
      "gobierno confía en que corte constitucional dé vía libre al mecanismo fast track\n",
      "bogotá, 04 de diciembre _ ram_ así lo confirmó este sábado el ministro del interior juan fernando cristo, quien señaló que: \"el gobierno emprenderá el camino de implementación del nuevo acuerdo de paz que decida la corte constitucional\", y confía en que la decisión sobre la vía rápida para la implementación de las leyes de paz se tome antes de la vacancia judicial y el fin de esta legislatura en el congreso, \"tenemos la fe de que va a dar salidas que garanticen implementación rápida de los acuerdos\".\n",
      "1\tgobierno\tgobierno\tNOUN\tncms000\tGender=Masc|Number=Sing\t2\tnsubj\t_\tCharOffset=0:8\n",
      "2\tconfía\tconfiar\tVERB\tvmip3s0\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\tCharOffset=9:15\n",
      "3\ten\ten\tADP\tsps00\t_\t7\tmark\t_\tCharOffset=16:18\n",
      "4\tque\tque\tSCONJ\tcs\t_\t7\tmark\t_\tCharOffset=19:22\n",
      "5\tcorte\tcorte\tNOUN\tncfs000\tGender=Fem|Number=Sing\t7\tnsubj\t_\tCharOffset=23:28\n",
      "6\tconstitucional\tconstitucional\tADJ\taq0cs0\tNumber=Sing\t5\tamod\t_\tCharOffset=29:43\n",
      "7\tdé\tdar\tVERB\tvmsp3s0\tMood=Sub|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t2\tccomp\t_\tCharOffset=44:46\n",
      "8\tvía\tvía\tNOUN\tncfs000\tGender=Fem|Number=Sing\t7\tobj\t_\tCharOffset=47:50\n",
      "9\tlibre\tlibre\tADJ\taq0cs0\tNumber=Sing\t8\tamod\t_\tCharOffset=51:56\n",
      "10\ta\ta\tADP\tspcms\t_\t12\tcase\t_\t_\n",
      "11\tel\tel\tDET\t_\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t12\tdet\t_\t_\n",
      "12\tmecanismo\tmecanismo\tNOUN\tncms000\tGender=Masc|Number=Sing\t7\tobl:arg\t_\tCharOffset=60:69\n",
      "13\tfast\tfast\tPROPN\tnp00000\t_\t12\tappos\t_\tCharOffset=70:74\n",
      "14\ttrack\ttrack\tPROPN\t_\t_\t13\tflat\t_\tCharOffset=75:80\n",
      "15\t-\t-\tPUNCT\tfg\tPunctType=Dash\t16\tpunct\t_\tCharOffset=81:82\n",
      "16\teje21\teje21\tADJ\taq0ms0\tNumber=Sing\t13\tflat\t_\tCharOffset=83:88\n",
      "17\tgobierno\tgobierno\tNOUN\tncms000\tGender=Masc|Number=Sing\t13\tflat\t_\tCharOffset=89:97\n",
      "18\tconfía\tconfiar\tVERB\tvmip3s0\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t2\tparataxis\t_\tCharOffset=98:104\n",
      "19\ten\ten\tADP\tsps00\t_\t23\tmark\t_\tCharOffset=105:107\n",
      "20\tque\tque\tSCONJ\tcs\t_\t23\tmark\t_\tCharOffset=108:111\n",
      "21\tcorte\tcorte\tNOUN\tncfs000\tGender=Fem|Number=Sing\t23\tnsubj\t_\tCharOffset=112:117\n",
      "22\tconstitucional\tconstitucional\tADJ\taq0cs0\tNumber=Sing\t21\tamod\t_\tCharOffset=118:132\n",
      "23\tdé\tdar\tVERB\tvmsp3s0\tMood=Sub|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t18\tccomp\t_\tCharOffset=133:135\n",
      "24\tvía\tvía\tNOUN\tncfs000\tGender=Fem|Number=Sing\t23\tobj\t_\tCharOffset=136:139\n",
      "25\tlibre\tlibre\tADJ\taq0cs0\tNumber=Sing\t24\tamod\t_\tCharOffset=140:145\n",
      "26\ta\ta\tADP\tspcms\t_\t28\tcase\t_\t_\n",
      "27\tel\tel\tDET\t_\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t28\tdet\t_\t_\n",
      "28\tmecanismo\tmecanismo\tNOUN\tncms000\tGender=Masc|Number=Sing\t23\tobl:arg\t_\tCharOffset=149:158\n",
      "29\tfast\tfast\tPROPN\tnp00000\t_\t28\tappos\t_\tCharOffset=159:163\n",
      "30\ttrack\ttrack\tPROPN\t_\t_\t29\tflat\t_\tCharOffset=164:169\n",
      "31\tbogotá\tbogotá\tPROPN\t_\t_\t29\tflat\t_\tCharOffset=170:176\n",
      "32\t,\t,\tPUNCT\tfc\tPunctType=Comm\t33\tpunct\t_\tCharOffset=176:177\n",
      "33\t04\t04\tNUM\t_\tNumForm=Digit|NumType=Card\t29\tappos\t_\tCharOffset=178:180\n",
      "34\tde\tde\tADP\t_\t_\t35\tcase\t_\tCharOffset=181:183\n",
      "35\tdiciembre\tdiciembre\tPROPN\t_\t_\t33\tnmod\t_\tCharOffset=184:193\n",
      "36\t_\t_\tPUNCT\tfc\t_\t37\tcase\t_\tCharOffset=194:195\n",
      "37\tram_\tram_\tNOUN\tncms000\t_\t33\tnmod\t_\tCharOffset=196:200\n",
      "38\tasí\tasí\tADV\trg\t_\t40\tadvmod\t_\tCharOffset=201:204\n",
      "39\tlo\tél\tPRON\tpp3msa00\tCase=Acc|Gender=Masc|Number=Sing|Person=3|PrepCase=Npr|PronType=Prs\t40\tobj\t_\tCharOffset=205:207\n",
      "40\tconfirmó\tconfirmar\tVERB\tvmis3s0\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t23\tadvcl\t_\tCharOffset=208:216\n",
      "41\teste\teste\tDET\tdd0ms0\tGender=Masc|Number=Sing|PronType=Dem\t42\tdet\t_\tCharOffset=217:221\n",
      "42\tsábado\tsábado\tNOUN\t_\t_\t40\tobl\t_\tCharOffset=222:228\n",
      "43\tel\tel\tDET\tda0ms0\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t44\tdet\t_\tCharOffset=229:231\n",
      "44\tministro\tministro\tNOUN\tncms000\tGender=Masc|Number=Sing\t40\tnsubj\t_\tCharOffset=232:240\n",
      "45\tde\tde\tADP\tspcms\t_\t47\tcase\t_\t_\n",
      "46\tel\tel\tDET\t_\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t47\tdet\t_\t_\n",
      "47\tinterior\tinterior\tNOUN\tncms000\tGender=Masc|Number=Sing\t44\tnmod\t_\tCharOffset=245:253\n",
      "48\tjuan\tjuan\tPROPN\tnp00000\t_\t44\tappos\t_\tCharOffset=254:258\n",
      "49\tfernando\tfernando\tPROPN\t_\t_\t48\tflat\t_\tCharOffset=259:267\n",
      "50\tcristo\tcristo\tPROPN\t_\t_\t48\tflat\t_\tCharOffset=268:274\n",
      "51\t,\t,\tPUNCT\tfc\tPunctType=Comm\t53\tpunct\t_\tCharOffset=274:275\n",
      "52\tquien\tquien\tPRON\tpr0cs000\tNumber=Sing|PronType=Rel\t53\tnsubj\t_\tCharOffset=276:281\n",
      "53\tseñaló\tseñalar\tVERB\tvmis3s0\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t44\tacl\t_\tCharOffset=282:288\n",
      "54\tque\tque\tSCONJ\tcs\t_\t59\tmark\t_\tCharOffset=289:292\n",
      "55\t:\t:\tPUNCT\tfd\tPunctType=Colo\t59\tpunct\t_\tCharOffset=292:293\n",
      "56\t\"\t\"\tPUNCT\tfe\tPunctType=Quot\t59\tpunct\t_\tCharOffset=294:295\n",
      "57\tel\tel\tDET\tda0ms0\tDefinite=Def|Gender=Masc|Number=Sing|PronType=Art\t58\tdet\t_\tCharOffset=295:297\n",
      "58\tgobierno\tgobierno\tNOUN\tncms000\tGender=Masc|Number=Sing\t59\tnsubj\t_\tCharOffset=298:306\n",
      "59\temprenderá\temprender\tVERB\tvmif3s0\tMood=Ind|Number=Sing|Person=3|Tense=Fut|VerbForm=Fin\t53\tccomp\t_\tCharOffset=307:317\n",
      "60\tel\tel\tDET\tda0\n"
     ]
    }
   ],
   "source": [
    "print(len(conllu_output))\n",
    "print(conllu_output[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35b333",
   "metadata": {},
   "source": [
    "## 2.4 Guardar la salida\n",
    "Guardamos ahora la salida del text_to_conllu en un archivo (entrada.conllu) que se usará como entrada del modelo a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64cf700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como entrada.conllu\n"
     ]
    }
   ],
   "source": [
    "file_name = \"entrada.conllu\"\n",
    "\n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(conllu_output)\n",
    "\n",
    "print(f\"Archivo guardado como {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
