{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50f6625",
   "metadata": {},
   "source": [
    "# Preprocesar\n",
    "En este archivo vamos a preprocesar el texto de manera que busquemos la mejor manera de sacar las etiquetas de cada tipo de palabra (POS tagging). El texto que vamos a usar va a estar en español, por lo que tenemos que usar modelos y métodos que lo soporten y tener en cuenta la sintaxis de dicho idioma. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c98d9",
   "metadata": {},
   "source": [
    "# 1 Sacar etiquetas\n",
    "Como hemos mencionado antes, vamos a sacar las etiquetas de cada palabra en un texto, comprobaremos el funcionamiento de varios modelos y discutiremos con cuál nos quedamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684f939",
   "metadata": {},
   "source": [
    "## 1.1 Imports\n",
    "El primer paso es definir los imports que vamos a usar durante esta parte, así como descargar datos para dichos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17330b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import stanza\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb132b",
   "metadata": {},
   "source": [
    "La celda de abajo solo es necesaria una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a8dbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_dep_news_trf')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccc515c69344a8dadc42a4d4a7fab04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 19:47:17 INFO: Downloaded file to C:\\Users\\Jorge\\stanza_resources\\resources.json\n",
      "2026-01-05 19:47:17 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2026-01-05 19:47:18 INFO: File exists: C:\\Users\\Jorge\\stanza_resources\\es\\default.zip\n",
      "2026-01-05 19:47:22 INFO: Finished downloading models and saved to C:\\Users\\Jorge\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('es_core_news_sm')\n",
    "print('-'*80)\n",
    "spacy.cli.download('es_dep_news_trf')\n",
    "print('-'*80)\n",
    "stanza.download('es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4497d3",
   "metadata": {},
   "source": [
    "## 1.2 Corpus de prueba\n",
    "Antes de pasar a la acción definimos un corpus de prueba para evaluar los modelos.En este vamos a tener todas las frases que vayamos a usar a lo largo de todo el preprocesamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295f6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'El gato come pescado.',\n",
    "    'El equipo de fútbol jugó su partido. Este ganó con facilidad.',\n",
    "    'El coche rojo se estropeó, así que lo llevé al taller.',\n",
    "    'La presidenta y el director se reunieron; ella habló primero.',\n",
    "    'Entregué el informe a la jefa después de que ella lo leyera.',\n",
    "    'Los equipos trabajaron duro, y al final ellos ganaron el premio.',\n",
    "    'A pesar de sus problemas, el artista terminó su obra.',\n",
    "    'El hermano de María dijo que él vendría.',\n",
    "    'En su oficina, el abogado revisó los documentos.',\n",
    "    'El libro que leí es fascinante; este autor siempre sorprende.',\n",
    "    'El gato persiguió al ratón, pero este logró escapar.',\n",
    "    'Hablé con Pedro sobre su proyecto y luego él me envió los archivos.',\n",
    "    'Ayer hablé con Juan, le dije: \"dímelo, por favor\", y no me lo quiso decir',\n",
    "    'Dímelo',\n",
    "    'Dí me lo',\n",
    "    'Di me lo',\n",
    "    'Él vino a dármelo',\n",
    "    \"La cabra de mi amigo Juan arremete todos los días contra la valla.\",\n",
    "    \"Mi madre me dijo: 'cómete la tarta', por lo que me la comí.\",\n",
    "    \"Mi profesor me dijo: 'comete este error y suspenderás', por lo que tuve mucho cuidado.\"\n",
    "    \"No sé si viste ayer a mi padre, pero yo sí.\",\n",
    "    \"Vístete rápido, que ya nos vamos.\",\n",
    "    \"Muéstrame tu chaqueta nueva.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d9128",
   "metadata": {},
   "source": [
    "## 1.3 Pruebas\n",
    "Vamos a empezar a probar modelos sobre todas las frases que hemos definido antes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165e67c",
   "metadata": {},
   "source": [
    "### 1.3.1 Spacy - es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63491e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado ADJ\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "Este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "al ADP\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "La DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADV\n",
      ". PUNCT\n",
      "\n",
      "Entregué PROPN\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "Los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADJ\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "al ADP\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "A ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "María PROPN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "En ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "libro NOUN\n",
      "que PRON\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "al ADP\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "Hablé PROPN\n",
      "con ADP\n",
      "Pedro PROPN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "Ayer ADV\n",
      "hablé NOUN\n",
      "con ADP\n",
      "Juan PROPN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo NOUN\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "Dímelo PROPN\n",
      "\n",
      "Dí PROPN\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Di PROPN\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo NOUN\n",
      "\n",
      "La DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "Juan PROPN\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta NOUN\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la DET\n",
      "comí NOUN\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás PROPN\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado NOUN\n",
      ". PUNCT\n",
      "No ADV\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí INTJ\n",
      ". PUNCT\n",
      "\n",
      "Vístete INTJ\n",
      "rápido ADJ\n",
      ", PUNCT\n",
      "que PRON\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "Muéstrame PROPN\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "test1 = []\n",
    "for text in corpus: test1.append(nlp(text))\n",
    "for doc in test1:\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c4ca6",
   "metadata": {},
   "source": [
    "En general lo hace muy bien, aunque confunde VERB que comienzan una oración con PROPN (sustantivos propios) y, en la primera oración, confunde el sustantivo pescado por el adjetivo, por lo que podemos intuir que cometerá más veces ese error. Por lo que a nuestra futura tarea respecta, el primer error puede ser garrafal, pues podría pensar el modelo que un pronombre se refiere a un verbo de esos mal etiquetados. Además, el verbo decir más los enclíticos me y lo lo considera un sustantivo, fallo enorme ya que son dos pronombres tras el verbo.\n",
    "Veamos el resto de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294abe9",
   "metadata": {},
   "source": [
    "### 1.3.2 Spacy - es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980978e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "Este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "al ADP\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "La DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADV\n",
      ". PUNCT\n",
      "\n",
      "Entregué VERB\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "Los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADV\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "al ADP\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "A ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "María PROPN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "En ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "libro NOUN\n",
      "que PRON\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "al ADP\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "Hablé VERB\n",
      "con ADP\n",
      "Pedro PROPN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "Ayer ADV\n",
      "hablé VERB\n",
      "con ADP\n",
      "Juan PROPN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo VERB\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "Dímelo VERB\n",
      "\n",
      "Dí AUX\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Di VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo VERB\n",
      "\n",
      "La DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "Juan PROPN\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta NOUN\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la PRON\n",
      "comí VERB\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás VERB\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado NOUN\n",
      ". PUNCT\n",
      "No ADV\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí ADV\n",
      ". PUNCT\n",
      "\n",
      "Vístete VERB\n",
      "rápido ADV\n",
      ", PUNCT\n",
      "que SCONJ\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "Muéstrame VERB\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_dep_news_trf\")\n",
    "test2 = []\n",
    "for text in corpus: test2.append(nlp(text))\n",
    "for doc in test2:\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a823bc",
   "metadata": {},
   "source": [
    "En este caso vemos que corrige todos los errores previos, salvo el caso de los enclíticos, que los considera verbos (bien, pero solo la raíz es el verbo). Esto muestra que este modelo es mejor, pero no perfecto, pues confunde, por ejemplo \"Dí\", de separar los enclíticos en \"Dímelo\", por AUX, pero sin la tilde dice correctamente que es un verbo, esto lo tendremos en cuenta más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c45678",
   "metadata": {},
   "source": [
    "### 1.3.3 Spacy - es_dep_news_trf (texto en minúsculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676a1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "al ADP\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "la DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADV\n",
      ". PUNCT\n",
      "\n",
      "entregué VERB\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADV\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "al ADP\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "a ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "maría PROPN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "en ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "libro NOUN\n",
      "que PRON\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "al ADP\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "hablé VERB\n",
      "con ADP\n",
      "pedro PROPN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "ayer ADV\n",
      "hablé VERB\n",
      "con ADP\n",
      "juan PROPN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo VERB\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "dímelo VERB\n",
      "\n",
      "dí VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "di VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo VERB\n",
      "\n",
      "la DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "juan PROPN\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta NOUN\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la PRON\n",
      "comí VERB\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' SYM\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás VERB\n",
      "' SYM\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado.no NOUN\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí ADV\n",
      ". PUNCT\n",
      "\n",
      "vístete VERB\n",
      "rápido ADV\n",
      ", PUNCT\n",
      "que SCONJ\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "muéstrame VERB\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_dep_news_trf\")\n",
    "test3 = []\n",
    "for text in corpus: test3.append(nlp(text.lower()))\n",
    "for doc in test3:\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efaebc",
   "metadata": {},
   "source": [
    "Al hacer varias pruebas nos damos cuenta que estos modelos son <em>case sensitive</em>, es decir, las palabras en mayúsculas y minúsculas importan. En este caso vemos que se solventa el problema del AUX en \"dí\", pero aún así palabras como \"dímelo\" no las hace bien. Probemos con otro modelo, en este caso Stanza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8304fc2",
   "metadata": {},
   "source": [
    "### 1.3.4 Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "Este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "a ADP\n",
      "el DET\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "La DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADV\n",
      ". PUNCT\n",
      "\n",
      "Entregué VERB\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "Los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADJ\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "a ADP\n",
      "el DET\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "A ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "María PROPN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "En ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "libro NOUN\n",
      "que PRON\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "El DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "a ADP\n",
      "el DET\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "Hablé VERB\n",
      "con ADP\n",
      "Pedro PROPN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "Ayer ADV\n",
      "hablé VERB\n",
      "con ADP\n",
      "Juan PROPN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo INTJ\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "Dímelo PROPN\n",
      "\n",
      "Dí VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Di INTJ\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "Él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo NOUN\n",
      "\n",
      "La DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "Juan PROPN\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta PROPN\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la PRON\n",
      "comí VERB\n",
      ". PUNCT\n",
      "\n",
      "Mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás VERB\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado NOUN\n",
      ". PUNCT\n",
      "No ADV\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí INTJ\n",
      ". PUNCT\n",
      "\n",
      "Vístete NOUN\n",
      "rápido ADJ\n",
      ", PUNCT\n",
      "que PRON\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "Muéstrame VERB\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('es', verbose=False)\n",
    "test4 = []\n",
    "for text in corpus: test4.append(nlp(text))\n",
    "for doc in test4:\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            print(word.text, word.pos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb05151",
   "metadata": {},
   "source": [
    "En este caso el modelo funciona muy similar a Spacy con es_dep_news_trf. Tampoco identifica correctamente los pronombres en \"dímelo\", y en este caso lo marca como interjección (INTJ). Cuando solo ponemos el verbo con enclíticos (Dímelo) lo considera verbo, y cuando lo separamos con espacios las partes analiza bien los pronombres pero el verbo vuelve a confundirlo con interjección, aunque si el verbo está sin tilde lo sigue marcanto como INTJ. Probemos con el texto en minúsculas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6226e",
   "metadata": {},
   "source": [
    "### 1.3.5 Stanza (minúsculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f9364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "a ADP\n",
      "el DET\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "la DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADV\n",
      ". PUNCT\n",
      "\n",
      "entregué VERB\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADJ\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "a ADP\n",
      "el DET\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "a ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "maría NOUN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "en ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "libro NOUN\n",
      "que PRON\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "a ADP\n",
      "el DET\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "hablé VERB\n",
      "con ADP\n",
      "pedro NOUN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "ayer ADV\n",
      "hablé VERB\n",
      "con ADP\n",
      "juan PROPN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo INTJ\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "dímelo NOUN\n",
      "\n",
      "dí VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "di VERB\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo NOUN\n",
      "\n",
      "la DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "juan PROPN\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta PROPN\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la PRON\n",
      "comí VERB\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás VERB\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado NOUN\n",
      ".no ADV\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí INTJ\n",
      ". PUNCT\n",
      "\n",
      "vístete NOUN\n",
      "rápido ADJ\n",
      ", PUNCT\n",
      "que PRON\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "muéstrame VERB\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('es', verbose=False)\n",
    "test5 = []\n",
    "for text in corpus: test5.append(nlp(text.lower()))\n",
    "for doc in test5:\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            print(word.text, word.pos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d65e9",
   "metadata": {},
   "source": [
    "Aquí cambia ligeramente: \"di\" lo marca bien como verbo, mientras que \"dímelo\" lo marca como sustantivo, y lo demás se mantiene igual. Aunque sea parecido a Spacy, este parece menos consistente con verbos con enclíticos. Ahora probamos con el último modelo, Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc2435",
   "metadata": {},
   "source": [
    "### 1.3.6 Stanza (distinto Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15481015",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    \"es\",\n",
    "    processors=\"tokenize,mwt,pos,lemma\",\n",
    "    tokenize_no_ssplit=False, \n",
    ")\n",
    "\n",
    "for text in corpus:\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sentences:\n",
    "        for w in sent.words:\n",
    "            print(w.text, w.lemma, w.upos)#, w.feats)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a1aaa28",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word' object has no attribute 'ner'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc.sentences:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent.words:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         \u001b[38;5;28mprint\u001b[39m(word.text, word.lemma, word.upos, word.xpos, \u001b[43mword\u001b[49m\u001b[43m.\u001b[49m\u001b[43mner\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Word' object has no attribute 'ner'"
     ]
    }
   ],
   "source": [
    "# 2. Inicializar Pipeline\n",
    "nlp = stanza.Pipeline(\n",
    "    lang='es',\n",
    "    processors='tokenize,mwt,pos,lemma,ner',\n",
    "    use_gpu=False,\n",
    "    pos_batch_size=2000\n",
    ")\n",
    "\n",
    "# 3. Procesar texto\n",
    "texto = \"Dármelo ahora, pásalo bien por favor.\"\n",
    "texto2 = \"Me gusta mi coche, ayer vine a comprarlo.\"\n",
    "texto3 = \"Me pasé toda la tarde jugándolo\"\n",
    "doc = nlp(texto2)\n",
    "\n",
    "# 4. Imprimir resultados con POS y lemma\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(word.text, word.lemma, word.upos, word.xpos, word.ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eff236",
   "metadata": {},
   "source": [
    "### 1.3.7 Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d263f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 20:03:17,324 SequenceTagger predicts: Dictionary with 17 tags: NOUN, PUNCT, ADP, VERB, ADJ, DET, PROPN, ADV, PRON, AUX, CCONJ, NUM, SCONJ, PART, X, SYM, INTJ\n",
      "el DET\n",
      "gato NOUN\n",
      "come VERB\n",
      "pescado NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "equipo NOUN\n",
      "de ADP\n",
      "fútbol NOUN\n",
      "jugó VERB\n",
      "su DET\n",
      "partido NOUN\n",
      ". PUNCT\n",
      "este PRON\n",
      "ganó VERB\n",
      "con ADP\n",
      "facilidad NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "coche NOUN\n",
      "rojo ADJ\n",
      "se PRON\n",
      "estropeó VERB\n",
      ", PUNCT\n",
      "así ADV\n",
      "que CCONJ\n",
      "lo PRON\n",
      "llevé VERB\n",
      "al DET\n",
      "taller NOUN\n",
      ". PUNCT\n",
      "\n",
      "la DET\n",
      "presidenta NOUN\n",
      "y CCONJ\n",
      "el DET\n",
      "director NOUN\n",
      "se PRON\n",
      "reunieron VERB\n",
      "; PUNCT\n",
      "ella PRON\n",
      "habló VERB\n",
      "primero ADJ\n",
      ". PUNCT\n",
      "\n",
      "entregué VERB\n",
      "el DET\n",
      "informe NOUN\n",
      "a ADP\n",
      "la DET\n",
      "jefa NOUN\n",
      "después ADV\n",
      "de ADP\n",
      "que SCONJ\n",
      "ella PRON\n",
      "lo PRON\n",
      "leyera VERB\n",
      ". PUNCT\n",
      "\n",
      "los DET\n",
      "equipos NOUN\n",
      "trabajaron VERB\n",
      "duro ADJ\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "al ADP\n",
      "final NOUN\n",
      "ellos PRON\n",
      "ganaron VERB\n",
      "el DET\n",
      "premio NOUN\n",
      ". PUNCT\n",
      "\n",
      "a ADP\n",
      "pesar NOUN\n",
      "de ADP\n",
      "sus DET\n",
      "problemas NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "artista NOUN\n",
      "terminó VERB\n",
      "su DET\n",
      "obra NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "hermano NOUN\n",
      "de ADP\n",
      "maría NOUN\n",
      "dijo VERB\n",
      "que SCONJ\n",
      "él PRON\n",
      "vendría VERB\n",
      ". PUNCT\n",
      "\n",
      "en ADP\n",
      "su DET\n",
      "oficina NOUN\n",
      ", PUNCT\n",
      "el DET\n",
      "abogado NOUN\n",
      "revisó VERB\n",
      "los DET\n",
      "documentos NOUN\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "libro NOUN\n",
      "que SCONJ\n",
      "leí VERB\n",
      "es AUX\n",
      "fascinante ADJ\n",
      "; PUNCT\n",
      "este DET\n",
      "autor NOUN\n",
      "siempre ADV\n",
      "sorprende VERB\n",
      ". PUNCT\n",
      "\n",
      "el DET\n",
      "gato NOUN\n",
      "persiguió VERB\n",
      "al DET\n",
      "ratón NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "este PRON\n",
      "logró VERB\n",
      "escapar VERB\n",
      ". PUNCT\n",
      "\n",
      "hablé VERB\n",
      "con ADP\n",
      "pedro NOUN\n",
      "sobre ADP\n",
      "su DET\n",
      "proyecto NOUN\n",
      "y CCONJ\n",
      "luego ADV\n",
      "él PRON\n",
      "me PRON\n",
      "envió VERB\n",
      "los DET\n",
      "archivos NOUN\n",
      ". PUNCT\n",
      "\n",
      "ayer ADV\n",
      "hablé VERB\n",
      "con ADP\n",
      "juan NOUN\n",
      ", PUNCT\n",
      "le PRON\n",
      "dije VERB\n",
      ": PUNCT\n",
      "\" PUNCT\n",
      "dímelo NOUN\n",
      ", PUNCT\n",
      "por ADP\n",
      "favor NOUN\n",
      "\" PUNCT\n",
      ", PUNCT\n",
      "y CCONJ\n",
      "no ADV\n",
      "me PRON\n",
      "lo PRON\n",
      "quiso VERB\n",
      "decir VERB\n",
      "\n",
      "dímelo NOUN\n",
      "\n",
      "dí VERB\n",
      "me PRON\n",
      "lo VERB\n",
      "\n",
      "di ADP\n",
      "me PRON\n",
      "lo PRON\n",
      "\n",
      "él PRON\n",
      "vino VERB\n",
      "a ADP\n",
      "dármelo NOUN\n",
      "\n",
      "la DET\n",
      "cabra NOUN\n",
      "de ADP\n",
      "mi DET\n",
      "amigo NOUN\n",
      "juan ADJ\n",
      "arremete VERB\n",
      "todos DET\n",
      "los DET\n",
      "días NOUN\n",
      "contra ADP\n",
      "la DET\n",
      "valla NOUN\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "madre NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "cómete VERB\n",
      "la DET\n",
      "tarta NOUN\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "me PRON\n",
      "la PRON\n",
      "comí VERB\n",
      ". PUNCT\n",
      "\n",
      "mi DET\n",
      "profesor NOUN\n",
      "me PRON\n",
      "dijo VERB\n",
      ": PUNCT\n",
      "' PUNCT\n",
      "comete VERB\n",
      "este DET\n",
      "error NOUN\n",
      "y CCONJ\n",
      "suspenderás VERB\n",
      "' PUNCT\n",
      ", PUNCT\n",
      "por ADP\n",
      "lo PRON\n",
      "que PRON\n",
      "tuve VERB\n",
      "mucho DET\n",
      "cuidado.no NOUN\n",
      "sé VERB\n",
      "si SCONJ\n",
      "viste VERB\n",
      "ayer ADV\n",
      "a ADP\n",
      "mi DET\n",
      "padre NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "yo PRON\n",
      "sí INTJ\n",
      ". PUNCT\n",
      "\n",
      "vístete NOUN\n",
      "rápido ADJ\n",
      ", PUNCT\n",
      "que SCONJ\n",
      "ya ADV\n",
      "nos PRON\n",
      "vamos VERB\n",
      ". PUNCT\n",
      "\n",
      "muéstrame VERB\n",
      "tu DET\n",
      "chaqueta NOUN\n",
      "nueva ADJ\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo POS (multilingual)\n",
    "tagger = SequenceTagger.load(\"pos-multi\")\n",
    "\n",
    "for text in corpus:\n",
    "    sentence = Sentence(text.lower())\n",
    "    tagger.predict(sentence)\n",
    "    for token in sentence:\n",
    "        print(token.text, token.get_labels()[0].value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9a851",
   "metadata": {},
   "source": [
    "En este modelo vemos más inconsistencias todavía. \"di\" lo marca como ADP, y \"lo\" al separar \"dímelo\" lo marca como verbo. No mejora en ningún aspecto a los anteriores. <br>\n",
    "Para mejorar este comportamiento vamos a hacer un preprocesamiento personalizado, el cual tratará de separar los enclíticos, pero para ello tenemos que ver qué verbos tienen enclíticos y cuáles no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8448b",
   "metadata": {},
   "source": [
    "# 2 Preprocesamiento personalizado\n",
    "Tras varias pruebas pensamos que el Spacy con dep news (texto en minúsculas) es el más consistente, ya que solo falla en los enclíticos. Para mejorar con los enclíticos podemos hacer nuestro propio preprocesamiento al texto para que así lo etiquete como debe.  \n",
    "En primer lugar vamos a probar a utilizar un stemmer para sacar la raíz de las palabras, de esta forma vamos a ver si las etiquetas se mantienen como antes y, además, resuelve los verbos con enclíticos y los verbos con falsos enclíticos (i.e. verbos como \"comete\", \"viste\", etc.). Idealmente queremos que se lematicen los verbos sin enclíticos y los que sí los tienen los deje igual para luego separarlos. \n",
    "Si esto no funciona como esperamos entonces cogeremos la lista de pronombres que pueden ir junto a los verbos y los ponemos en orden (i.e. nunca se tiene \"lasme\", siempre \"melas\", como en \"dámelas\"). Pero esto solo no es suficiente, puesto que hay verbos que tienen \"me\", \"te\" u otros. Pero comete es diferente de cómete, de comer, por lo que necesitamos una lista con verbos a los que no les tenemos que aplicar este preprocesamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250484e3",
   "metadata": {},
   "source": [
    "## 2.1 Imports\n",
    "Primero definimos los imports que usaremos en esta parte, al igual que hicimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f81e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef4a3b",
   "metadata": {},
   "source": [
    "## 2.2 Funciones auxiliares\n",
    "Para no repetir código, vamos a definir una o varias funciones auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0812cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(corpus: list[str] = []):\n",
    "    nlp = spacy.load(\"es_dep_news_trf\")\n",
    "    docs = []\n",
    "    for text in corpus: docs.append(nlp(text.lower()))\n",
    "    return docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17049d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tags(docs: list, stems: list, compare: list):\n",
    "    for doc, cmp, stem_phrase in zip(docs, compare, stems):\n",
    "        for doc_token, cmp_token, stem in zip(doc, cmp, stem_phrase):\n",
    "            if doc_token.pos_ != cmp_token.pos_:\n",
    "                print('-'*40, '\\n', \n",
    "                      doc_token.text, stem, doc_token.pos_, '|', cmp_token.text, cmp_token.pos_,\n",
    "                      '\\n', '-'*40)\n",
    "            print(doc_token.text, stem, doc_token.pos_, '|', cmp_token.text, cmp_token.pos_)\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d99a7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tags(docs: list = [], stems: list = [], compare: list | None = None):\n",
    "    if compare:\n",
    "        compare_tags(docs, stems, compare)\n",
    "    else:\n",
    "        for doc in docs:\n",
    "            for token, stem in zip(doc, stems):\n",
    "                print(token.text, stem, token.pos_)\n",
    "            print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778b71e",
   "metadata": {},
   "source": [
    "## 2.3 Pruebas\n",
    "Vamos ahora a probar los modelos para arreglar el fallo con los enclíticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a1adc",
   "metadata": {},
   "source": [
    "### 2.3.1 LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c353af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el el DET | el DET\n",
      "gato gato NOUN | gato NOUN\n",
      "come com VERB | come VERB\n",
      "pescado pescado NOUN | pescado NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "equipo equipo NOUN | equipo NOUN\n",
      "de de ADP | de ADP\n",
      "fútbol fútbol NOUN | fútbol NOUN\n",
      "jugó jugó VERB | jugó VERB\n",
      "su su DET | su DET\n",
      "partido partido NOUN | partido NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "este est PRON | este PRON\n",
      "ganó ganó VERB | ganó VERB\n",
      "con con ADP | con ADP\n",
      "facilidad facilidad NOUN | facilidad NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "coche coch NOUN | coche NOUN\n",
      "rojo rojo ADJ | rojo ADJ\n",
      "se se PRON | se PRON\n",
      "estropeó estropeó VERB | estropeó VERB\n",
      ", , PUNCT | , PUNCT\n",
      "así así ADV | así ADV\n",
      "que que SCONJ | que SCONJ\n",
      "lo lo PRON | lo PRON\n",
      "llevé llevé VERB | llevé VERB\n",
      "al al ADP | al ADP\n",
      "taller tal NOUN | taller NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "la la DET | la DET\n",
      "presidenta president NOUN | presidenta NOUN\n",
      "y y CCONJ | y CCONJ\n",
      "el el DET | el DET\n",
      "director direct NOUN | director NOUN\n",
      "se se PRON | se PRON\n",
      "reunieron reunieron VERB | reunieron VERB\n",
      "; ; PUNCT | ; PUNCT\n",
      "ella ell PRON | ella PRON\n",
      "habló habló VERB | habló VERB\n",
      "primero primero ADV | primero ADV\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "entregué entregué VERB | entregué VERB\n",
      "el el DET | el DET\n",
      "informe inform NOUN | informe NOUN\n",
      "a a ADP | a ADP\n",
      "la la DET | la DET\n",
      "jefa jef NOUN | jefa NOUN\n",
      "después despué ADV | después ADV\n",
      "de de ADP | de ADP\n",
      "que que SCONJ | que SCONJ\n",
      "ella ell PRON | ella PRON\n",
      "lo lo PRON | lo PRON\n",
      "leyera leyer VERB | leyera VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "los los DET | los DET\n",
      "equipos equipo NOUN | equipos NOUN\n",
      "trabajaron trabajaron VERB | trabajaron VERB\n",
      "duro duro ADV | duro ADV\n",
      ", , PUNCT | , PUNCT\n",
      "y y CCONJ | y CCONJ\n",
      "al al ADP | al ADP\n",
      "final fin NOUN | final NOUN\n",
      "ellos ello PRON | ellos PRON\n",
      "ganaron ganaron VERB | ganaron VERB\n",
      "el el DET | el DET\n",
      "premio premio NOUN | premio NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "a a ADP | a ADP\n",
      "pesar pes NOUN | pesar NOUN\n",
      "de de ADP | de ADP\n",
      "sus sus DET | sus DET\n",
      "problemas problema NOUN | problemas NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "el el DET | el DET\n",
      "artista artist NOUN | artista NOUN\n",
      "terminó terminó VERB | terminó VERB\n",
      "su su DET | su DET\n",
      "obra obr NOUN | obra NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "hermano hermano NOUN | hermano NOUN\n",
      "de de ADP | de ADP\n",
      "maría marí PROPN | maría PROPN\n",
      "dijo dijo VERB | dijo VERB\n",
      "que que SCONJ | que SCONJ\n",
      "él él PRON | él PRON\n",
      "vendría vendrí VERB | vendría VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "en en ADP | en ADP\n",
      "su su DET | su DET\n",
      "oficina oficin NOUN | oficina NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "el el DET | el DET\n",
      "abogado abogado NOUN | abogado NOUN\n",
      "revisó revisó VERB | revisó VERB\n",
      "los los DET | los DET\n",
      "documentos documento NOUN | documentos NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "libro libro NOUN | libro NOUN\n",
      "que que PRON | que PRON\n",
      "leí leí VERB | leí VERB\n",
      "es es AUX | es AUX\n",
      "fascinante fascin ADJ | fascinante ADJ\n",
      "; ; PUNCT | ; PUNCT\n",
      "este est DET | este DET\n",
      "autor aut NOUN | autor NOUN\n",
      "siempre siempr ADV | siempre ADV\n",
      "sorprende sorprend VERB | sorprende VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "gato gato NOUN | gato NOUN\n",
      "persiguió persiguió VERB | persiguió VERB\n",
      "al al ADP | al ADP\n",
      "ratón ratón NOUN | ratón NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "pero pero CCONJ | pero CCONJ\n",
      "este est PRON | este PRON\n",
      "logró logró VERB | logró VERB\n",
      "escapar escap VERB | escapar VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "hablé hablé VERB | hablé VERB\n",
      "con con ADP | con ADP\n",
      "pedro pedro PROPN | pedro PROPN\n",
      "sobre sobr ADP | sobre ADP\n",
      "su su DET | su DET\n",
      "proyecto proyecto NOUN | proyecto NOUN\n",
      "y y CCONJ | y CCONJ\n",
      "luego luego ADV | luego ADV\n",
      "él él PRON | él PRON\n",
      "me me PRON | me PRON\n",
      "envió envió VERB | envió VERB\n",
      "los los DET | los DET\n",
      "archivos archivo NOUN | archivos NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "ayer ay ADV | ayer ADV\n",
      "hablé hablé VERB | hablé VERB\n",
      "con con ADP | con ADP\n",
      "juan juan PROPN | juan PROPN\n",
      ", , PUNCT | , PUNCT\n",
      "le le PRON | le PRON\n",
      "dije dij VERB | dije VERB\n",
      ": : PUNCT | : PUNCT\n",
      "\" `` PUNCT | \" PUNCT\n",
      "dímelo dímelo VERB | dímelo VERB\n",
      ", , PUNCT | , PUNCT\n",
      "por por ADP | por ADP\n",
      "favor fav NOUN | favor NOUN\n",
      "\" '' PUNCT | \" PUNCT\n",
      ", , PUNCT | , PUNCT\n",
      "y y CCONJ | y CCONJ\n",
      "no no ADV | no ADV\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "quiso quiso VERB | quiso VERB\n",
      "decir decir VERB | decir VERB\n",
      "\n",
      "dímelo dímelo VERB | dímelo VERB\n",
      "\n",
      "dí dí VERB | dí VERB\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "\n",
      "di di VERB | di VERB\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "\n",
      "la la DET | la DET\n",
      "cabra cabr NOUN | cabra NOUN\n",
      "de de ADP | de ADP\n",
      "mi mi DET | mi DET\n",
      "amigo amigo NOUN | amigo NOUN\n",
      "juan juan PROPN | juan PROPN\n",
      "arremete arremet VERB | arremete VERB\n",
      "todos todo DET | todos DET\n",
      "los los DET | los DET\n",
      "días día NOUN | días NOUN\n",
      "contra contr ADP | contra ADP\n",
      "la la DET | la DET\n",
      "valla vall NOUN | valla NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "mi mi DET | mi DET\n",
      "madre madr NOUN | madre NOUN\n",
      "me me PRON | me PRON\n",
      "dijo dijo VERB | dijo VERB\n",
      ": : PUNCT | : PUNCT\n",
      "' 'cómete SYM | ' SYM\n",
      "cómete la VERB | cómete VERB\n",
      "la tart DET | la DET\n",
      "tarta ' NOUN | tarta NOUN\n",
      "' , SYM | ' SYM\n",
      ", por PUNCT | , PUNCT\n",
      "por lo ADP | por ADP\n",
      "lo que PRON | lo PRON\n",
      "que me PRON | que PRON\n",
      "me la PRON | me PRON\n",
      "la comí PRON | la PRON\n",
      "comí . VERB | comí VERB\n",
      "\n",
      "mi mi DET | mi DET\n",
      "profesor profes NOUN | profesor NOUN\n",
      "me me PRON | me PRON\n",
      "dijo dijo VERB | dijo VERB\n",
      ": : PUNCT | : PUNCT\n",
      "' 'comete SYM | ' SYM\n",
      "comete est VERB | comete VERB\n",
      "este er DET | este DET\n",
      "error y NOUN | error NOUN\n",
      "y suspenderá CCONJ | y CCONJ\n",
      "suspenderás ' VERB | suspenderás VERB\n",
      "' , SYM | ' SYM\n",
      ", por PUNCT | , PUNCT\n",
      "por lo ADP | por ADP\n",
      "lo que PRON | lo PRON\n",
      "que tuv PRON | que PRON\n",
      "tuve mucho VERB | tuve VERB\n",
      "mucho cuidado.no DET | mucho DET\n",
      "cuidado.no sé NOUN | cuidado.no NOUN\n",
      "sé si VERB | sé VERB\n",
      "si vist SCONJ | si SCONJ\n",
      "viste ay VERB | viste VERB\n",
      "ayer a ADV | ayer ADV\n",
      "a mi ADP | a ADP\n",
      "mi padr DET | mi DET\n",
      "padre , NOUN | padre NOUN\n",
      ", pero PUNCT | , PUNCT\n",
      "pero yo CCONJ | pero CCONJ\n",
      "yo sí PRON | yo PRON\n",
      "sí . ADV | sí ADV\n",
      "\n",
      "vístete vístete VERB | vístete VERB\n",
      "rápido rápido ADV | rápido ADV\n",
      ", , PUNCT | , PUNCT\n",
      "que que SCONJ | que SCONJ\n",
      "ya ya ADV | ya ADV\n",
      "nos nos PRON | nos PRON\n",
      "vamos vamo VERB | vamos VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "muéstrame muéstram VERB | muéstrame VERB\n",
      "tu tu DET | tu DET\n",
      "chaqueta chaquet NOUN | chaqueta NOUN\n",
      "nueva nuev ADJ | nueva ADJ\n",
      ". . PUNCT | . PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_list = [word_tokenize(text.lower(), language=\"spanish\") for text in corpus]\n",
    "stemmer = LancasterStemmer()\n",
    "stems = []\n",
    "for token_phrase in tokens_list:\n",
    "    stems.append([stemmer.stem(token) for token in token_phrase])\n",
    "\n",
    "docs = pos_tag(corpus)\n",
    "print_tags(docs, stems, test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124ce17",
   "metadata": {},
   "source": [
    "Vemos que evalúa exactamente igual que con el texto. Además, algunos verbos con enclíticos los lematiza de forma que se pierde el pronombre (e.g. muéstrame lo lematiza como muéstram), por lo que no nos sirve este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121cd3a",
   "metadata": {},
   "source": [
    "### 2.3.2 SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c274ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el el DET | el DET\n",
      "gato gat NOUN | gato NOUN\n",
      "come com VERB | come VERB\n",
      "pescado pesc NOUN | pescado NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "equipo equip NOUN | equipo NOUN\n",
      "de de ADP | de ADP\n",
      "fútbol futbol NOUN | fútbol NOUN\n",
      "jugó jug VERB | jugó VERB\n",
      "su su DET | su DET\n",
      "partido part NOUN | partido NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "este este PRON | este PRON\n",
      "ganó gan VERB | ganó VERB\n",
      "con con ADP | con ADP\n",
      "facilidad facil NOUN | facilidad NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "coche coch NOUN | coche NOUN\n",
      "rojo roj ADJ | rojo ADJ\n",
      "se se PRON | se PRON\n",
      "estropeó estrope VERB | estropeó VERB\n",
      ", , PUNCT | , PUNCT\n",
      "así asi ADV | así ADV\n",
      "que que SCONJ | que SCONJ\n",
      "lo lo PRON | lo PRON\n",
      "llevé llev VERB | llevé VERB\n",
      "al al ADP | al ADP\n",
      "taller tall NOUN | taller NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "la la DET | la DET\n",
      "presidenta president NOUN | presidenta NOUN\n",
      "y y CCONJ | y CCONJ\n",
      "el el DET | el DET\n",
      "director director NOUN | director NOUN\n",
      "se se PRON | se PRON\n",
      "reunieron reun VERB | reunieron VERB\n",
      "; ; PUNCT | ; PUNCT\n",
      "ella ella PRON | ella PRON\n",
      "habló habl VERB | habló VERB\n",
      "primero primer ADV | primero ADV\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "entregué entreg VERB | entregué VERB\n",
      "el el DET | el DET\n",
      "informe inform NOUN | informe NOUN\n",
      "a a ADP | a ADP\n",
      "la la DET | la DET\n",
      "jefa jef NOUN | jefa NOUN\n",
      "después despues ADV | después ADV\n",
      "de de ADP | de ADP\n",
      "que que SCONJ | que SCONJ\n",
      "ella ella PRON | ella PRON\n",
      "lo lo PRON | lo PRON\n",
      "leyera leyer VERB | leyera VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "los los DET | los DET\n",
      "equipos equip NOUN | equipos NOUN\n",
      "trabajaron trabaj VERB | trabajaron VERB\n",
      "duro dur ADV | duro ADV\n",
      ", , PUNCT | , PUNCT\n",
      "y y CCONJ | y CCONJ\n",
      "al al ADP | al ADP\n",
      "final final NOUN | final NOUN\n",
      "ellos ellos PRON | ellos PRON\n",
      "ganaron gan VERB | ganaron VERB\n",
      "el el DET | el DET\n",
      "premio premi NOUN | premio NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "a a ADP | a ADP\n",
      "pesar pes NOUN | pesar NOUN\n",
      "de de ADP | de ADP\n",
      "sus sus DET | sus DET\n",
      "problemas problem NOUN | problemas NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "el el DET | el DET\n",
      "artista artist NOUN | artista NOUN\n",
      "terminó termin VERB | terminó VERB\n",
      "su su DET | su DET\n",
      "obra obra NOUN | obra NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "hermano herman NOUN | hermano NOUN\n",
      "de de ADP | de ADP\n",
      "maría mar PROPN | maría PROPN\n",
      "dijo dij VERB | dijo VERB\n",
      "que que SCONJ | que SCONJ\n",
      "él el PRON | él PRON\n",
      "vendría vendr VERB | vendría VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "en en ADP | en ADP\n",
      "su su DET | su DET\n",
      "oficina oficin NOUN | oficina NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "el el DET | el DET\n",
      "abogado abog NOUN | abogado NOUN\n",
      "revisó revis VERB | revisó VERB\n",
      "los los DET | los DET\n",
      "documentos document NOUN | documentos NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "libro libr NOUN | libro NOUN\n",
      "que que PRON | que PRON\n",
      "leí lei VERB | leí VERB\n",
      "es es AUX | es AUX\n",
      "fascinante fascin ADJ | fascinante ADJ\n",
      "; ; PUNCT | ; PUNCT\n",
      "este este DET | este DET\n",
      "autor autor NOUN | autor NOUN\n",
      "siempre siempr ADV | siempre ADV\n",
      "sorprende sorprend VERB | sorprende VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "el el DET | el DET\n",
      "gato gat NOUN | gato NOUN\n",
      "persiguió persigu VERB | persiguió VERB\n",
      "al al ADP | al ADP\n",
      "ratón raton NOUN | ratón NOUN\n",
      ", , PUNCT | , PUNCT\n",
      "pero per CCONJ | pero CCONJ\n",
      "este este PRON | este PRON\n",
      "logró logr VERB | logró VERB\n",
      "escapar escap VERB | escapar VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "hablé habl VERB | hablé VERB\n",
      "con con ADP | con ADP\n",
      "pedro pedr PROPN | pedro PROPN\n",
      "sobre sobr ADP | sobre ADP\n",
      "su su DET | su DET\n",
      "proyecto proyect NOUN | proyecto NOUN\n",
      "y y CCONJ | y CCONJ\n",
      "luego lueg ADV | luego ADV\n",
      "él el PRON | él PRON\n",
      "me me PRON | me PRON\n",
      "envió envi VERB | envió VERB\n",
      "los los DET | los DET\n",
      "archivos archiv NOUN | archivos NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "ayer ayer ADV | ayer ADV\n",
      "hablé habl VERB | hablé VERB\n",
      "con con ADP | con ADP\n",
      "juan juan PROPN | juan PROPN\n",
      ", , PUNCT | , PUNCT\n",
      "le le PRON | le PRON\n",
      "dije dij VERB | dije VERB\n",
      ": : PUNCT | : PUNCT\n",
      "\" `` PUNCT | \" PUNCT\n",
      "dímelo dimel VERB | dímelo VERB\n",
      ", , PUNCT | , PUNCT\n",
      "por por ADP | por ADP\n",
      "favor favor NOUN | favor NOUN\n",
      "\" '' PUNCT | \" PUNCT\n",
      ", , PUNCT | , PUNCT\n",
      "y y CCONJ | y CCONJ\n",
      "no no ADV | no ADV\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "quiso quis VERB | quiso VERB\n",
      "decir dec VERB | decir VERB\n",
      "\n",
      "dímelo dimel VERB | dímelo VERB\n",
      "\n",
      "dí di VERB | dí VERB\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "\n",
      "di di VERB | di VERB\n",
      "me me PRON | me PRON\n",
      "lo lo PRON | lo PRON\n",
      "\n",
      "la la DET | la DET\n",
      "cabra cabr NOUN | cabra NOUN\n",
      "de de ADP | de ADP\n",
      "mi mi DET | mi DET\n",
      "amigo amig NOUN | amigo NOUN\n",
      "juan juan PROPN | juan PROPN\n",
      "arremete arremet VERB | arremete VERB\n",
      "todos tod DET | todos DET\n",
      "los los DET | los DET\n",
      "días dias NOUN | días NOUN\n",
      "contra contr ADP | contra ADP\n",
      "la la DET | la DET\n",
      "valla vall NOUN | valla NOUN\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "mi mi DET | mi DET\n",
      "madre madr NOUN | madre NOUN\n",
      "me me PRON | me PRON\n",
      "dijo dij VERB | dijo VERB\n",
      ": : PUNCT | : PUNCT\n",
      "' 'comet SYM | ' SYM\n",
      "cómete la VERB | cómete VERB\n",
      "la tart DET | la DET\n",
      "tarta ' NOUN | tarta NOUN\n",
      "' , SYM | ' SYM\n",
      ", por PUNCT | , PUNCT\n",
      "por lo ADP | por ADP\n",
      "lo que PRON | lo PRON\n",
      "que me PRON | que PRON\n",
      "me la PRON | me PRON\n",
      "la com PRON | la PRON\n",
      "comí . VERB | comí VERB\n",
      "\n",
      "mi mi DET | mi DET\n",
      "profesor profesor NOUN | profesor NOUN\n",
      "me me PRON | me PRON\n",
      "dijo dij VERB | dijo VERB\n",
      ": : PUNCT | : PUNCT\n",
      "' 'comet SYM | ' SYM\n",
      "comete este VERB | comete VERB\n",
      "este error DET | este DET\n",
      "error y NOUN | error NOUN\n",
      "y suspend CCONJ | y CCONJ\n",
      "suspenderás ' VERB | suspenderás VERB\n",
      "' , SYM | ' SYM\n",
      ", por PUNCT | , PUNCT\n",
      "por lo ADP | por ADP\n",
      "lo que PRON | lo PRON\n",
      "que tuv PRON | que PRON\n",
      "tuve much VERB | tuve VERB\n",
      "mucho cuidado.n DET | mucho DET\n",
      "cuidado.no se NOUN | cuidado.no NOUN\n",
      "sé si VERB | sé VERB\n",
      "si vist SCONJ | si SCONJ\n",
      "viste ayer VERB | viste VERB\n",
      "ayer a ADV | ayer ADV\n",
      "a mi ADP | a ADP\n",
      "mi padr DET | mi DET\n",
      "padre , NOUN | padre NOUN\n",
      ", per PUNCT | , PUNCT\n",
      "pero yo CCONJ | pero CCONJ\n",
      "yo si PRON | yo PRON\n",
      "sí . ADV | sí ADV\n",
      "\n",
      "vístete vistet VERB | vístete VERB\n",
      "rápido rap ADV | rápido ADV\n",
      ", , PUNCT | , PUNCT\n",
      "que que SCONJ | que SCONJ\n",
      "ya ya ADV | ya ADV\n",
      "nos nos PRON | nos PRON\n",
      "vamos vam VERB | vamos VERB\n",
      ". . PUNCT | . PUNCT\n",
      "\n",
      "muéstrame muestram VERB | muéstrame VERB\n",
      "tu tu DET | tu DET\n",
      "chaqueta chaquet NOUN | chaqueta NOUN\n",
      "nueva nuev ADJ | nueva ADJ\n",
      ". . PUNCT | . PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_list = [word_tokenize(text.lower(), language=\"spanish\") for text in corpus]\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "stems = []\n",
    "for token_phrase in tokens_list:\n",
    "    stems.append([stemmer.stem(token) for token in token_phrase])\n",
    "\n",
    "docs = pos_tag(corpus)\n",
    "print_tags(docs, stems, test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006efa56",
   "metadata": {},
   "source": [
    "Este caso funciona igual que el anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ff196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "CLITICS = ['me','te','se','lo','la','los','las','le','les','nos','os']\n",
    "\n",
    "# construye combos posibles (hasta 2 clíticos en la práctica; hay casos de 3 pero raros)\n",
    "def generate_clitic_combos():\n",
    "    combos = set()\n",
    "    # uno\n",
    "    for c in CLITICS:\n",
    "        combos.add(c)\n",
    "    # dos (orden correcto: primero clítico átono como me/te/se/nos/ se + lo/la/los/las/le/les)\n",
    "    for a in CLITICS:\n",
    "        for b in CLITICS:\n",
    "            combos.add(a + b)\n",
    "    # opcional: podrías añadir triples si lo necesitas\n",
    "    return sorted(combos, key=lambda x: -len(x))  # orden largo -> corto\n",
    "\n",
    "CLITIC_COMBOS = generate_clitic_combos()\n",
    "\n",
    "def analyze_text(nlp, text):\n",
    "    \"\"\"Analiza text y devuelve el primer word analysis (upos, feats, lemma) si existe.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    # si hay oraciones y words:\n",
    "    if doc.sentences and doc.sentences[0].words:\n",
    "        w = doc.sentences[0].words[0]\n",
    "        return {'text': w.text, 'upos': w.upos, 'feats': w.feats or '', 'lemma': w.lemma}\n",
    "    return None\n",
    "\n",
    "def is_pronoun_like(nlp, token_text):\n",
    "    a = analyze_text(nlp, token_text)\n",
    "    return a is not None and (a['upos'] == 'PRON' or a['upos'] == 'DET')  # DET para artículos si aplicara\n",
    "\n",
    "def try_split_token(nlp, token_text):\n",
    "    \"\"\"\n",
    "    Devuelve lista de sub-tokens si decide dividir, \n",
    "    o [token_text] si no dividir.\n",
    "    \"\"\"\n",
    "    token_text_orig = token_text\n",
    "    token_text_lower = token_text_orig.lower()\n",
    "\n",
    "    # 1) analiza token completo\n",
    "    full = analyze_text(nlp, token_text_orig)\n",
    "    # Si Stanza lo considera verbo 3ª pers. indicativo -> probablemente no es enclítico\n",
    "    if full and full['upos'] == 'VERB' and 'Person=3' in full['feats'] and 'Mood=Imp' not in (full['feats'] or ''):\n",
    "        return [token_text_orig]  # no dividimos\n",
    "\n",
    "    # 2) intentamos splits por combinaciones de clíticos (de más largo a más corto)\n",
    "    for combo in CLITIC_COMBOS:\n",
    "        if token_text_lower.endswith(combo):\n",
    "            left = token_text_orig[:len(token_text_orig)-len(combo)]\n",
    "            right = token_text_orig[len(token_text_orig)-len(combo):]\n",
    "            if not left: \n",
    "                continue\n",
    "\n",
    "            # valida que cada pieza derecha se componga en pronombres conocidos (por si combo es raro)\n",
    "            # descomponer right en secuencias de clíticos (intento simple: probar particion en 1..n)\n",
    "            # para simplicidad, si combo está en la lista CLITICS o es concatenación válida, lo aceptamos provisionalmente\n",
    "            # comprobación morfológica:\n",
    "            left_a = analyze_text(nlp, left)\n",
    "            right_a = analyze_text(nlp, right)\n",
    "\n",
    "            # Conditions to accept split:\n",
    "            # - left exists and is VERB\n",
    "            # - right exists and is PRON (o sequence of PRONs)  (aquí cheque simple)\n",
    "            if left_a and left_a['upos'] == 'VERB' and right_a and right_a['upos'] == 'PRON':\n",
    "                # Heurística adicional: el verbo izquierdo debe mostrarse como imperativo o 2ª persona\n",
    "                feats = (left_a['feats'] or '')\n",
    "                if 'Mood=Imp' in feats or 'Person=2' in feats or 'VerbForm=Fin' in feats:\n",
    "                    return [left, right]\n",
    "                # otra heurística: si la forma original NO era verbo 3ª persona (evitamos 'comete' -> 'come+te')\n",
    "                if not (full and full['upos']=='VERB' and 'Person=3' in full['feats']):\n",
    "                    return [left, right]\n",
    "                # otherwise continue searching combos\n",
    "\n",
    "    # si no encontramos nada aceptable\n",
    "    return [token_text_orig]\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "texts = [\"Él comete errores.\", \"Vete al norte.\", \"Cómete la manzana.\", \"comete\", \"dinos\"]\n",
    "for text in corpus:\n",
    "    print(\"===\", text)\n",
    "    # tokeniza rápido por espacio (ejemplo); en uso real recorre doc.sentences.tokens\n",
    "    for tok in text.split():\n",
    "        subtoks = try_split_token(nlp, tok)\n",
    "        print(tok, \"->\", subtoks)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de clíticos españoles\n",
    "CLITICOS = [\"me\",\"te\",\"se\",\"lo\",\"la\",\"los\",\"las\",\"le\",\"les\",\"nos\",\"os\"]\n",
    "\n",
    "# Orden típico permitido en español\n",
    "# (simplificado pero suficientemente bueno para casi todos los casos)\n",
    "ORDEN_CLITICOS = [\n",
    "    [\"me\",\"lo\"], [\"me\",\"la\"], [\"me\",\"los\"], [\"me\",\"las\"],\n",
    "    [\"te\",\"lo\"], [\"te\",\"la\"], [\"te\",\"los\"], [\"te\",\"las\"],\n",
    "    [\"se\",\"lo\"], [\"se\",\"la\"], [\"se\",\"los\"], [\"se\",\"las\"],\n",
    "    [\"nos\",\"lo\"], [\"nos\",\"la\"], [\"nos\",\"los\"], [\"nos\",\"las\"],\n",
    "    [\"os\",\"lo\"], [\"os\",\"la\"], [\"os\",\"los\"], [\"os\",\"las\"],\n",
    "]\n",
    "\n",
    "# Generar patrones de clíticos pegados (ej: \"melo\", \"telo\", \"selo\")\n",
    "PATRONES = sorted(\n",
    "    [ \"\".join(p) for p in ORDEN_CLITICOS ] + CLITICOS,\n",
    "    key=len, reverse=True\n",
    ")\n",
    "\n",
    "VERBOS = [\n",
    "    \"comete\",\n",
    "    \"somete\",\n",
    "    \"arremete\",\n",
    "    \"promete\",\n",
    "    \"remete\",\n",
    "    \"entromete\",\n",
    "    \"admite\",\n",
    "    \"emite\",\n",
    "    \"omite\",\n",
    "    \"remite\",\n",
    "    \"permite\",\n",
    "    \"transmite\",\n",
    "    \"dimite\",\n",
    "    \"limite\",\n",
    "    \"intermite\",\n",
    "    \"retransmite\",\n",
    "    \"siente\",\n",
    "    \"consiente\",\n",
    "    \"presiente\",\n",
    "    \"resiente\",\n",
    "    \"asiente\",\n",
    "    \"disiente\",\n",
    "    \"resume\",\n",
    "    \"asume\",\n",
    "    \"presume\",\n",
    "    \"consume\",\n",
    "    \"subsume\",\n",
    "    \"come\",\n",
    "    \"vale\",\n",
    "    'comeríamos'\n",
    "] # Aún faltan muchísimos, igual mejor guardarlo como txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_cliticos(token, lemma):\n",
    "    \"\"\"\n",
    "    Separa clíticos de una forma verbal como 'dímelo', 'háblalo', 'cómetelo', etc.\n",
    "    \"\"\"\n",
    "    t = token.lower()\n",
    "\n",
    "    # Buscar si termina en un clítico válido (simple o doble)\n",
    "    encontrados = []\n",
    "    resto = t\n",
    "\n",
    "    for patron in PATRONES:\n",
    "        if resto.endswith(patron):\n",
    "            encontrados.append(patron)          # ej: \"melo\"\n",
    "            resto = resto[: -len(patron)]\n",
    "            break\n",
    "\n",
    "    # Si no encontró nada → no hay clíticos pegados\n",
    "    if not encontrados:\n",
    "        return [token]  \n",
    "\n",
    "    # Convertir el verbo a su forma verbal (usar lemma como base)\n",
    "    raiz = lemma\n",
    "\n",
    "    # Normalizar la raíz para modo imperativo (caso típico)\n",
    "    # Esto no es perfecto, pero funciona para mayoría:\n",
    "    if raiz.endswith(\"r\"):      # comer → come\n",
    "        raiz = raiz[:-1]\n",
    "    elif raiz.endswith(\"irse\"): # \"irse\" → \"ir\" pero con reflexivos es complejo\n",
    "        raiz = raiz[:-3]\n",
    "\n",
    "    resultado = [raiz]\n",
    "\n",
    "    # Ahora separar los clíticos (simple o doble)\n",
    "    cl = encontrados[0]\n",
    "\n",
    "    # Si es doble clítico (\"melo\", \"selo\", etc.)\n",
    "    for c in CLITICOS:\n",
    "        if cl.startswith(c):\n",
    "            resto2 = cl[len(c):]\n",
    "            if c in CLITICOS:\n",
    "                resultado.append(c)\n",
    "            if resto2 in CLITICOS:\n",
    "                resultado.append(resto2)\n",
    "            break\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5f7e4",
   "metadata": {},
   "source": [
    "### OTRA FORMA DE SEPARAR CLÍTICOS - LISTA DE EXCEPCIONES + REGLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0edd9f",
   "metadata": {},
   "source": [
    "Como podemos observar, stanza tiene bastantes carencias a la hora de reconocer y separar los clíticos en español siendo que solo es bueno reconociendo los infinitivos con clíticos y los gerundios cuando solo tienen un clítico, si presentan doble clítico no los reconoce. Por eso, cualquier forma verbal en imperativo con clíticos fallará a la hora de reconocerla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497927c5",
   "metadata": {},
   "source": [
    "#### EJEMPLO VERBO JUGAR\n",
    "\n",
    "| Forma verbal | Descripción | Stanza (salida incorrecta) | Deseado (análisis correcto) |\n",
    "|-------------|-------------|----------------------------|-----------------------------|\n",
    "| juégalo | Imperativo 2ª persona singular + 1 clítico | juégalo → juégalo (NOUN) | juega (jugar, VERB) + lo (él, PRON) |\n",
    "| juégatelo | Imperativo 2ª persona singular + 2 clíticos | juégatelo → juégatelo (NOUN) | juega (jugar, VERB) + te (tú, PRON) + lo (él, PRON) |\n",
    "| jugadle | Imperativo 2ª persona plural + 1 clítico | jugadle → jugadle (NOUN) | jugad (jugar, VERB) + le (él, PRON) |\n",
    "| jugádnoslo | Imperativo 2ª persona plural + 2 clíticos | jugadno → jugadno (NOUN) + lo (él, PRON) | jugad (jugar, VERB) + nos (nosotros, PRON) + lo (él, PRON) |\n",
    "| juéguelo | Imperativo 2ª persona singular (usted) + 1 clítico | juéguelo → juéguelo (NOUN) | juegue (jugar, VERB) + lo (él, PRON) |\n",
    "| juégueselo | Imperativo 2ª persona singular (usted) + 2 clíticos | juégueselo → juégueselo (NOUN) | juegue (jugar, VERB) + se (él, PRON) + lo (él, PRON) |\n",
    "| jueguenlo | Imperativo 2ª persona plural (ustedes) + 1 clítico | jueguenlo → jueguenlo (NOUN) | jueguen (jugar, VERB) + lo (él, PRON) |\n",
    "| jueguenselo | Imperativo 2ª persona plural (ustedes) + 2 clíticos | jueguenselo → jueguenselo (NOUN) | jueguen (jugar, VERB) + se (él, PRON) + lo (él, PRON) |\n",
    "| juguémoslo | Imperativo 1ª persona plural + 1 clítico | juguémoslo → juguémoslo (NOUN) | juguemos (jugar, VERB) + lo (él, PRON) |\n",
    "|juguémonoslo | Imperativo 1ª persona plural + 2 clítico | juguémonoslo -> juguémonoslo NOUN |juguemos (jugar, VERB) + nos (nosotros, PRON) + lo (él, PRON)|\n",
    "jugándomelo | Gerundio + 2 clíticos | jugando -> jugar VERB + melo -> melo NOUN | jugando (jugar, VERB) + me (yo, PRON) + lo (él, PRON)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca89688",
   "metadata": {},
   "source": [
    "Para ello meteremos estas formas verbales en una lista de excepciones para separarlas de forma manual y así pueden ser tokenizadas correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8a4de",
   "metadata": {},
   "source": [
    "#### IMPORTS\n",
    "- re: Librería para expresiones regulares\n",
    "- stanza: Librería para tokenizar texto en español\n",
    "- List y Dict: Librerías que representan listas y diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import stanza\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcbc24",
   "metadata": {},
   "source": [
    "#### LISTA DE VERBOS CON CLÍTICOS\n",
    "\n",
    "Lista de excepciones que el tokenizador de stanza no sabe tokenizar, típicamente son las formas imperativas de los verbos en español que presentan clíticos.\n",
    "\n",
    "Los verbos en la lista se reconocen mediante expresiones regulares de la base de la palabra y todas las combinaciones de clíticos que nos podemos encontrar en ella. También se especifica de que verbo viene ya que la base puede coincidir con alguna forma verbal de algún otro verbo como sucede con \"díselo\" cuya base es di que coincide con el pasado del verbo \"dar\". Por eso se le indica el lema al que pertenece y el upos ya que aunque todos sean verbos, el tokenizador no lo reconoce e intenta adivinarlo dándole alguna upos aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPERATIVE_MAP = {\n",
    "    # Verbo comer\n",
    "    r\"(?:C|c)óme((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"come\",\n",
    "        \"lemma\": \"comer\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:C|c)om[eé]d((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"comed\",\n",
    "        \"lemma\": \"comer\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo cometer\n",
    "    r\"(?:C|c)ométe((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"comete\",\n",
    "        \"lemma\": \"cometer\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:C|c)omet[eé]d((?:me|te|se|nos|os)?)((?:lo|le|la|los|les|las)?)\": {\n",
    "        \"base\": \"cometed\",\n",
    "        \"lemma\": \"cometer\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo vestir\n",
    "    r\"(?:v|V)íste((?:me|te|se|nos|os)?)((?:lo|la|los|las)?)\": {\n",
    "        \"base\": \"viste\",\n",
    "        \"lemma\": \"vestir\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo acostar\n",
    "    r\"(?:a|A)cués(?:ta|te)((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"acuesta\",\n",
    "        \"lemma\": \"acostar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:a|A)costad((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"acosta\",\n",
    "        \"lemma\": \"acostar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo decir\n",
    "    r\"(?:d|D)[íi]((?:me|te|se|nos|os)?)((?:le|lo|la|les|los|las)?)\": {\n",
    "        \"base\": \"di\",\n",
    "        \"lemma\": \"decir\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo mostrar\n",
    "    r\"(?:m|M)uéstra((?:me|te|se|nos|os)?)((?:lo|la|le|los|las|le)?)\": {\n",
    "        \"base\": \"muestra\",\n",
    "        \"lemma\": \"mostrar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Verbo jugar: Contempla todas las formas verbales en la que falla stanza\n",
    "    r\"(?:j|J)ugu[ée]mo((?:nos))((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"juguemo\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)uéguen((?:me|te|se|nos)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"jueguen\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)uguémos((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"juguemos\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)uég(?:a|ue)((?:me|te|se|nos)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"juega\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)ugáz((?:me|te|se|nos)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"jugad\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)ugáos((?:lo|la|los|las))\": {\n",
    "        \"base\": \"jugad\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    r\"(?:j|J)ugándo((?:me|te|se|nos)?)((?:lo|la|le|los|las|les)?)\": {\n",
    "        \"base\": \"jugando\",\n",
    "        \"lemma\": \"jugar\",\n",
    "        \"upos\": \"VERB\"\n",
    "    },\n",
    "    # Añadir más verbos según necesidad\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13556b",
   "metadata": {},
   "source": [
    "Lista de clíticos del español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLITICS = [\"me\", \"te\", \"se\", \"nos\", \"os\", \"lo\", \"la\", \"le\", \"los\", \"las\", \"les\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c106cf",
   "metadata": {},
   "source": [
    "**split_clitics**\n",
    "\n",
    "Separa los clíticos de la palabra original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clitics(clitic_string: str):\n",
    "    clitics = []\n",
    "    remaining = clitic_string\n",
    "\n",
    "    for cl in CLITICS:\n",
    "        if remaining.startswith(cl):\n",
    "            clitics.append(cl)\n",
    "            remaining = remaining[len(cl):]\n",
    "\n",
    "    return clitics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e1f06",
   "metadata": {},
   "source": [
    "**preprocess_imperatives**\n",
    "\n",
    "Coordina el proceso de limpieza del texto. Se descompone en 3 fases:\n",
    "\n",
    " 1º- Inicialización donde crea una lista (imperative_meta) que guardará la información de cada verbo que se modifique\n",
    "\n",
    " 2º- El Ciclo de Transformación donde recorrerá el IMPERATIVE_MAP con los patrones y las reglas de sustitución\n",
    "\n",
    " 3º- Actualización donde aplicará los cambios al texto original devolviéndolo junto con sus metadatos recolectados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b02de",
   "metadata": {},
   "source": [
    "**make_replacer**\n",
    "\n",
    "Se corresponde con el ciclo de transformación y se encargará de coger cada patrón junto con su regla asociada del IMPERATIVE_MAP. Además también devuelve la expresión regular lista para emplearse y la función replacer configurada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cd037",
   "metadata": {},
   "source": [
    "**replacer**\n",
    "\n",
    "Función que no llama el usuario sino que la llama el motor de expresiones regulares de python cada vez que encuentra una coincidencia que encaja con el patrón. Su funcionamiento es el siguiente:\n",
    "\n",
    " 1º- Captura los clíticos de la palabra, si no los hay, devuelve la palabra sin modificar\n",
    "\n",
    " 2º- Crea una nueva cadena de texto separando la raíz del verbo de los pronombre empleando espacios\n",
    "\n",
    " 3º- Guarda en imperative_meta la información técnica del verbo para que no se pierda la información que había aunque se cambie la palabra\n",
    "\n",
    " 4º- Asegura que respeta las mayúsculas que la palabra original tenía\n",
    "\n",
    " 5º- Devuelve la cadena separada para que se inserte en el texto originial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c21541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imperatives(text: str):\n",
    "    imperative_meta = []\n",
    "\n",
    "    def make_replacer(pattern: str, rule: Dict):\n",
    "        regex = re.compile(pattern, flags=re.IGNORECASE) # Carga la expresión regular del patrón\n",
    "\n",
    "        def replacer(match): # Si no coincide con el patrón, devuelve la palabra sin modificar\n",
    "            groups = match.groups() # Analiza el patrón para buscar que clíticos tiene\n",
    "            # Mete los clíticos encontrados como elementos de una lista\n",
    "            clitic_string = \"\".join(g for g in groups if g) if groups else \"\"\n",
    "            clitics = split_clitics(clitic_string)\n",
    "\n",
    "            # Si no hay clíticos, no tocar la palabra original\n",
    "            if not clitics:\n",
    "                return match.group(0)\n",
    "            \n",
    "            # Aplicar la regla correspondiente si hay clíticos\n",
    "            replacement = \" \".join([rule[\"base\"]] + clitics)\n",
    "\n",
    "            imperative_meta.append({\n",
    "                \"base\": rule[\"base\"],\n",
    "                \"lemma\": rule[\"lemma\"],\n",
    "                \"upos\": rule[\"upos\"]\n",
    "            })\n",
    "\n",
    "            # Mantener mayúscula inicial\n",
    "            if match.group(0)[0].isupper():\n",
    "                replacement = replacement.capitalize()\n",
    "\n",
    "            return replacement\n",
    "\n",
    "        return regex, replacer\n",
    "\n",
    "    for pattern, rule in IMPERATIVE_MAP.items():\n",
    "        regex, replacer = make_replacer(pattern, rule)\n",
    "        text = regex.sub(replacer, text) # Aplica la sustitución al texto original\n",
    "\n",
    "    return text, imperative_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2e82f",
   "metadata": {},
   "source": [
    "**parse_text**\n",
    "\n",
    "Función que separá los clíticos llamando a preprocess_imperatives para despues pasarlos por el tokenizador de stanza.pipeline y así tener ya cada palabra tokenizada para luego pasarla al formato final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04498f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text: str):\n",
    "    # Separar clíticos\n",
    "    preprocessed, imperative_meta = preprocess_imperatives(text)\n",
    "\n",
    "    # Tokenizar las palabras\n",
    "    doc = nlp(preprocessed)\n",
    "    \n",
    "    return doc, imperative_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468da319",
   "metadata": {},
   "source": [
    "**texto_a_frases**\n",
    "\n",
    "Convierte texto bruto en una lista de frases. Separa el texto cuando encuentra algún signo de puntuación que indique el fin de frase.\n",
    "\n",
    "Esto es necesario para llamar a la función texts_to_conllu (Notebook de formato conllu) ya que espera una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91adcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_a_frases(texto: str) -> list[str]:\n",
    "    if not texto or not texto.strip():\n",
    "        return []\n",
    "\n",
    "    # Normalizar espacios\n",
    "    texto = re.sub(r'\\s+', ' ', texto.strip())\n",
    "\n",
    "    # Separar por fin de frase\n",
    "    frases = re.split(r'(?<=[.!?¿¡])\\s+', texto)\n",
    "\n",
    "    # Limpiar frases vacías\n",
    "    return [f.strip() for f in frases if f.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b499e",
   "metadata": {},
   "source": [
    "# 3 Dataset\n",
    "Ahora vamos a buscar un dataset para sacar sus etiquetas part-of-speech (POS TAGs). Este dataset será el que después probaremos qué tal sirve nuestro modelo para resolver las referencias de los pronombres a los sustantivos. Hemos encontrado en Hugging Face un dataset llamado CulturaX, que tiene datos en más de 160 idiomas, entre ellos el español. Consideramos que es un dataset lo suficientemente completo con multitud de textos de diferentes procedencias para usarlo en nuestro proyecto. Vamos a coger un subset de varios miles de textos ya que el completo tiene millones o más, y no necesitamos tantos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde64f6",
   "metadata": {},
   "source": [
    "## 3.1 Imports\n",
    "Vamos a ver los imports que necesitamos y el login de Hugging Face.\n",
    "Si se quiere ejecutar la celda de abajo hay que seguir las instrucciones del login en notebook, es bastante intuitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e46e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b3c235262443cd8746d131571bd04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a06aa",
   "metadata": {},
   "source": [
    "## 3.2 Cargar textos\n",
    "Ahora vamos a cargar los textos en una variable 'ds_es', la cual funciona como Stream para no descargar los datos, solo metadatos que permiten su uso, y después vamos a tomar trivialmente 5 mil textos para nuestro proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8565d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c6e8a020ac47efb564d84bedf084c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_es = load_dataset(\n",
    "    \"uonlp/CulturaX\",  # Nombre del dataset\n",
    "    \"es\",              # Config de idioma español\n",
    "    streaming=True     # Stream para no descargar completo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3be2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Tomar solo los primeros n ejemplos\n",
    "n = 5000  \n",
    "subset = ds_es[\"train\"].take(n)\n",
    "\n",
    "# Convertir a lista si quieres verlos o trabajar con ellos\n",
    "data = list(subset)\n",
    "\n",
    "print(len(data))  # debería dar n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b46b76",
   "metadata": {},
   "source": [
    "## 3.3 Mostrar datos\n",
    "Para ver un poco los datos vamos a mostrar unos cuantos textos, primero veamos que tipo es cada cosa y cómo podemos acceder a dichos textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dac1ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47dcc3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'timestamp', 'url', 'source'])\n"
     ]
    }
   ],
   "source": [
    "print(data[1].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ebb60",
   "metadata": {},
   "source": [
    "Vemos que tiene 4 claves. Veamos cada campo, excepto texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b46ae00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://periodicoalminutosv.com/5072/nacionales/presidente-bukele-es-bien-evaluado-en-los-primeros-meses-de-su-gestion-90-de-la-poblacion-opina-que-esta-ayudando/\n",
      "OSCAR-2109\n",
      "2021-03-04T07:09:46Z\n"
     ]
    }
   ],
   "source": [
    "print(data[1]['url'])\n",
    "print(data[1]['source'])\n",
    "print(data[1]['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e3c8e",
   "metadata": {},
   "source": [
    "Se entiende bastante bien qué es cada cosa, excepto la fuente. Vamos a mostrar ahora los primeros 5 textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf2150b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gobierno confía en que Corte Constitucional dé vía libre al mecanismo fast track - Eje21\n",
      "Gobierno confía en que Corte Constitucional dé vía libre al mecanismo fast track\n",
      "Bogotá, 04 de diciembre _ RAM_ Así lo confirmó este sábado el ministro del Interior Juan Fernando Cristo, quien señaló que: \"el Gobierno emprenderá el camino de implementación del nuevo acuerdo de paz que decida la Corte Constitucional\", y confía en que la decisión sobre la vía rápida para la implementación de las leyes de paz se tome antes de la vacancia judicial y el fin de esta legislatura en el Congreso, \"tenemos la fe de que va a dar salidas que garanticen implementación rápida de los acuerdos\". \n",
      "\n",
      "hola yo estoy pasando por la misma situacion el 19 de diciembre pedi en mandarake ub shin mazinger , armadura blindada para vf 25 1/60 y el set para el vf 25 tornado y hasta el dia de hoy la pgina de correos de mexico solo dice recibido en oficina postal 2 evntos, la verdad no se para cuando llegue mi paquete es la primera vez que pido algo en diciembre, ya me esta preocupando\n",
      "te recomiendo que ni te preocupes hace unos meses pedi a HLJ por EMS mi tsumugi que tambien fue a finales de diciembre y se tardo como un mes en llegar pero siempre llegan y si no si es que lo pediste por EMS tienes la garantia\n",
      "Lo que pasa e que tengo una orden que ya esta lista en amiami, pero no se cuando pagarla, si mal no recuerdo tengo hasta el jueves para pagar.\n",
      "Este 2012 pedí cosas el 2 de enero, las pague el 3 y el 4 me las mandaron por registrado y me llegaron tres semanas después, que es lo normal del correo registrado. Si el registrado pasado el año nuevo jala bien, ems también debería jalar bien después de año nuevo. En este caso la warehouse de hlj te pude ser de mucha ayuda\n",
      "así solo pagas lo que quieres, te lo guardan hasta por dos meses y cuando lo desees, solicitas el envio. Con esto podrías librar la temporada navideña y tener lo que quieres comprar.\n",
      "Hola a todos, les cuento mi experiencia, yo compré dos figuras figma por amiami, es muy sencillo y es la primera vez que compro figuras por medio de este tipo, aparte esta página me ayudó mucho para saber como realizar este tipo de compras, bueno una vez que se concretó el pago en amiami me mandaron el número de tracking luego luego, hice mi compra por SAL registrado, como era mi primera vez y no sabía cuanto podría pesar mi envío pues me decidí por este tipo de envío, al día siguiente mi paquete ya estaba en JPost con registros de “Posting/Collection” y al poco rato con “Arrival at outward office of exchange”, al día siguiente generó el registro de “Dispatch from outward office of exchange”, todo va bien.\n",
      "A los días de checar el tracking en japon no generaba nuevos registros, entonces checaba sepomex y japanpost a ver si generaban registros, la verdad como era mi primera compra si me preocupé algo, pensaba hasta lo peor pero la tercer semana de a ver pedido mis figuras, generó un registro en Sepomex de que ya había llegado al país y estaban enviando a destino, de ahí los registros en sepomex son más rápidos y a la semana ya tenía mi paquete, tuve que ir por el personalmente ya que estaba por ser fin de semana y después navidad y quien sabe cuanto más tardarían en mandarlo aún cuando el registro de sepomex decía con mensajero y no lo mandaron el mismo día, bueno pues esa fue mi experiencia espero a alguien le sirva y no se desespere con la llegada de sus paquetes que llegan bien y a salvo sin ningun golpe y gracias a la página me sirvió de mucho.\n",
      "hola a todos alguien sabe si correos de mexico tiene problemas para actualizar su pagina ya que el dia de hoy no pude checar en la pagina mi compra que hice en mandarake el dia 18 de diciembre.\n",
      "Muy probablemente no se debe a que mexpost no actualice, sino a que aún no llega a méxico. Recuerda que es temporada alta, se cruzaron dos días festivos (el 25 y el 1), y en méxico no se trabaja esos días, si le sumas que en muchos lugares se trabaja medio día el 24 y 31, te darás una idea del desmadre que han de tener los de la aduana. Por si fuera poco, las cosas que entran al país en días festivos generalmente no tienen registros por varias semanas, es como si entraran en la dimensión desconocida, por lo menos hasta que regularicen el servicio. No te preocupes, te va a llegar tu paquete, pero va a tardar, en esta época los ems pueden tardar hasta un mes. Yo estoy en las mismas, en mi caso me enviaron cosas el 22 de diciembre, y aún no aparece nada en mexpost.\n",
      "Hola no se si ahora me toco perder jajaja tengo un paquete de Taiwan pendiente desde el 27 de noviembre 12.\n",
      "ya contacte al webmaster de la tienda y unicamente me dice que cheque la guia en el servicio de correo de mi pais.\n",
      "en en traking de taiwan dice que el envio salio el dia 27 de noviembre y en vuelo numero tal. pero no aparece nada de aduana. en su experiencia creen que tarde otras semanas en aparecer algo? o ya valio. \n",
      "\n",
      "'Sólo llegaremos a Marte si estamos dispuestos a arriesgar la vida' | Ciencia | EL MUNDO\n",
      "ENTREVISTA Walt Cunningham, ex astronauta de la NASA\n",
      "'Sólo llegaremos a Marte si estamos dispuestos a arriesgar la vida'\n",
      "PABLO JÁUREGUI Enviado especial Tenerife\n",
      "Actualizado: 29/09/2014 04:10 horas\n",
      "El 5 de mayo de 1961, Walt Cunningham -entonces un joven piloto en la Reserva de los Marines- estaba conduciendo tranquilamente por una carretera de California, pero no tuvo más remedio que frenar en seco. La emisora que escuchaba por la radio interrumpió su programación para emitir en directo la cuenta atrás del lanzamiento de Alan Shepard, el primer astronauta estadounidense, desde la base de Cabo Cañaveral. «Me pareció un momento tan increíble que no podía concentrarme. Tuve que parar el coche por miedo a pegármela», recuerda Cunningham. Cuando escuchó el rugido de aquel cohete despegando al espacio, este veterano de la Guerra de Corea no pudo reprimir su emoción y exclamó: «You lucky son of a bitch! [¡Qué suerte tienes, hijo de puta!]». Ese día, decidió que quería ser astronauta.\n",
      "Dos años después, tras someterse a una durísima serie de pruebas, el sueño de Cunningham se hizo realidad, hasta el punto de que le tocó compartir el mismo despacho con el propio Alan Shepard. Aquélla fue la edad dorada de la exploración espacial, cuando Kennedy prometió poner a un hombre en la Luna en menos de una década «no porque es fácil, sino porque es difícil», y Cunningham logró convertirse en uno de los pioneros que, como dijo Tom Wolfe, tuvieron the right stuff («lo que hay que tener») para culminar esta hazaña.\n",
      "De hecho, junto con sus compañeros Wally Schirra y Don Eisele, a Cunningham le tocó la dura tarea de volar por primera vez en una nave Apolo, después del trágico accidente que costó la vida a los tres tripulantes que inicialmente habían sido elegidos para esta aventura: Gus Grissom, Ed White y Roger Chaffee. En octubre de 1968, Cunningham y sus dos colegas pilotaron con éxito la primera misión tripulada del programa Apolo, en un vuelo de prueba que orbitó 163 veces alrededor de la Tierra, y dieron así el primer paso crucial hacia el «gran salto para la Humanidad» de Neil Armstrong.\n",
      "La semana pasada, este héroe de la carrera espacial visitó Tenerife para participar en el Festival Starmus, un congreso internacional concebido para divulgar los hallazgos de la astronomía a todos los públicos. Poco antes de hablar ante un auditorio abarrotado de jóvenes amantes del Cosmos, Cunningham concedió esta entrevista exclusiva a EL MUNDO.\n",
      "Walt Cunningham, durante la misión Apolo 7. NASA\n",
      "Después de que murieran sus compañeros del Apolo 1, ¿se planteó arrojar la toalla por temor a que pudiera pasarle lo mismo?\n",
      "Jamás, ni yo ni ninguno de mis compañeros. Todos habíamos formado parte de escuadrones militares y estábamos acostumbrados a perder a buenos amigos en la guerra o en accidentes. Eso formaba parte de nuestra vida. Claro que estábamos tristes, pero teníamos un sentido del deber que quizás se ha perdido en el mundo de hoy. Por eso, estábamos psicológicamente preparados para el desafío del programa Apolo. Todos sabíamos que podíamos morir en el intento, pero asumíamos ese riesgo. Nuestro único miedo era el miedo al fracaso.\n",
      "¿Qué es lo que más recuerda de su misión?\n",
      "Aunque parezca una banalidad, una de las cosas que más recuerdo es que Wally cayó enfermo con un resfriado el día después del lanzamiento y aquello nos dio mucha guerra. Por lo demás, durante la misión estábamos tan ocupados con la verificación de todos los sistemas de la nave que no tuvimos tiempo más que para trabajar y dormir.\n",
      "Pero me imagino que al menos disfrutó de las vistas. ¿Cómo fue la experiencia de ver la Tierra desde ahí fuera?\n",
      "Me impresionó muchísimo y no lo olvidaré jamás. Pero tampoco espere grandes pronunciamientos románticos por mi parte, no tuve ninguna experiencia mística o filosófica. Nuestra obsesión era la profesionalidad, hacer bien nuestro trabajo, no meter la pata en nada... ¡y lo conseguimos!\n",
      "¿Cómo vivió la rivalidad con los rusos en medio de la Guerra Fría?\n",
      "Pues la verdad es que sabíamos desde la mitad de los 60 que nuestra tecnología iba muy por delante de ellos. Las naves del programa Gemini de hace 40 años eran muchísimo más eficaces que las rusas. Sin embargo, hoy nosotros hemos perdido el empuje y la motivación que teníamos en el pasado para aprovechar nuestras capacidades tecnológicas, hasta el punto de que ahora mismo dependemos de Rusia para subir ahí arriba.\n",
      "¿Le resulta humillante esta dependencia actual de los rusos?\n",
      "No es humillante porque los rusos saben perfectamente de lo que somos capaces, pero me entristece muchísimo. Y lo peor de todo es que teníamos la mejor máquina voladora de todos los tiempos: el transbordador espacial. Para mí, el mayor error en la historia de la NASA fue la jubilación de los shuttle.\n",
      "Me sorprende que diga eso cuando los transbordadores sufrieron dos accidentes en los que murieron 14 astronautas. ¿No cree que tenían fallos graves de diseño?\n",
      "No, para nada, aquellas dos tragedias se debieron a errores administrativos, créame. Por ejemplo, en el caso de Challenger, que estalló al despegar debido al hielo acumulado en su exterior, incluso la tripulación había avisado a los controladores de la misión que no debían despegar ese día porque hacía demasiado frío. Y en el caso del Columbia, para ahorrar dinero modificaron el diseño de las losetas que debían proteger a la nave durante la reentrada en la atmósfera. El problema se conocía y se podía haber resuelto, pero no hicieron nada hasta que se produjo la catástrofe.\n",
      "En todo caso, si de usted dependiera, no hubiera jubilado a los transbordadores.\n",
      "¡Por supuesto! Jamás los hubiera retirado, era una nave asombrosa, una auténtica maravilla.\n",
      "¿Qué opina, entonces, del proyecto impulsado por Obama para desarrollar un nuevo vehículo que recupere la capacidad de la NASA para lanzar astronautas y culminar el sueño de llegar hasta Marte?\n",
      "Creo, por supuesto, que Marte debería ser nuestro gran objetivo, pero desafortunadamente la triste realidad es que no estamos haciendo lo necesario para lograrlo. Desde principios de los años 70 llevamos diciendo que después de la Luna, íbamos a viajar a Marte. Lo podíamos haber conseguido hace ya mucho tiempo. Pero con el tiempo, la NASA se ha ido volviendo cada vez más burocrática, con capas y más capas de funcionarios obsesionados con la seguridad e incapaces de asumir riesgos. Hoy la verdad es que soy muy pesimista. Dudo que cumplan con el calendario que han propuesto para llegar a Marte en torno a 2030.\n",
      "Pero antes de intentar ir a Marte, ¿cree que antes se debería viajar a un asteroide, como ha propuesto Obama, o quizás volver a la Luna, como escala previa?\n",
      "No me parecería mal que regresáramos primero a la Luna, pero únicamente con el objetivo de poner a prueba las tecnologías necesarias para llegar a Marte, sobre todo las instalaciones que nos permitan sobrevivir durante periodos largos allí. La idea de viajar a un asteroide, sin embargo, me parece una estúpida pérdida de tiempo. Pero lo más grave de todo es que a Obama no le interesa lo más mínimo el espacio.\n",
      "¿Y qué le parece la idea que defiende su colega del programa Apolo, Buzz Aldrin, de realizar un viaje a Marte sin billete de vuelta?\n",
      "He hablado mucho con Buzz de este tema, y él lo defiende porque no es tonto y sabe que es relativamente fácil llegar hasta Marte, pero mucho más difícil regresar a la Tierra desde tan lejos. Yo no estoy de acuerdo con que la NASA planifique una misión sin billete de vuelta, pero por supuesto deberíamos aceptar y asumir el riesgo de que quizás nuestros astronautas no regresen sanos y salvos desde allí.\n",
      "¿Siente nostalgia de la edad dorada del programa Apolo?\n",
      "Por supuesto, el problema fundamental es que hemos perdido la visión filosófica y la actitud psicológica que nos llevó hasta la Luna. Hemos educado a un par de generaciones a las que ya no desafiamos con grandes retos. Lo que te motiva y te inspira a llegar más lejos es la ambición de conquistar nuevas fronteras, pero hoy casi nadie está dispuesto a pagar el precio. Y no estoy hablando de dólares, estoy hablando de afrontar la incertidumbre de una aventura peligrosa, como las de Colón o Magallanes en el Nuevo Mundo. Para llegar a Marte, necesitamos recuperar esa mentalidad y estar dispuestos a asumir el riesgo de perder la vida para conseguirlo. No olvidemos que para preparar el viaje a la Luna, tres hombres, mis tres compañeros del Apolo 1, perecieron en el intento. Pero si hay un solo acontecimiento en el siglo XX que resistirá el paso del tiempo y se percibirá como un motivo para que la Humanidad esté orgullosa de sí misma, será la llegada del hombre a la Luna. Aceptamos aquel desafío, asumimos el riesgo y cambiamos el mundo.\n",
      "¿Qué le parece la ambición espacial de China?\n",
      "En estos momentos, los chinos tienen la mejor actitud que hay que tener para explorar el espacio. No tienen prisa, se están tomando su tiempo para ir mejorando sus capacidades y lanzar misiones cada vez más complejas. Los chinos son muy inteligentes y están logrando avances a mayor velocidad que nadie ahora mismo. Si Estados Unidos quiere volver a recuperar su liderazgo, tiene que hacer una apuesta firme como la que está haciendo China en estos momentos. De lo contrario, nos quedaremos atrás. Incluso los rusos, con su persistencia, pueden sobrepasarnos.\n",
      "Me parece inconcebible que no haya vida en otros lugares del Universo. Ahora bien, si me pregunta si alguna vez contactaremos con alienígenas, creo que no. Quizás, como mucho, captemos alguna señal de otra civilización. Pero si tenemos en cuenta que Alfa Centauri, la estrella más cercana, está a 4,3 años luz, me parece muy improbable. Todas las historias que circulan por ahí sobre platillos volantes son basura.\n",
      "Imaginemos dos granos de arena que son depositados en el mar en sitios opuestos del planeta y que las corrientes puedan desplazarlos a su libre albedrio. ¿Que posinlidad tienen de encontrarse a una distancia de menos de un metro?, la respuesta es casi ninguna. De haber vida extraterrestre la posibilidad de tropezar con ella seria tan remota que casi tiende a ninguna. Y de no haber vida, menuda cantidad de espacio desaprovechado.\n",
      "29/09/2014 15:50 horas\n",
      "Movernos hoy en día con los artefactos tan rudimentarios como los de los humanos, me parece atentar contra la vida. Son burdos y del pleistoceno. De aquí de este planeta no podemos escaparnos a ninguna parte fuera de este sistema solar, la humanidad no ha tomado conciencia de que estamos confinados. Y la humanidad sigue haciendo cárceles, y no se da cuenta de que vamos viajando en una cárcel grande, que no se escapa ni el gato.\n",
      "29/09/2014 14:03 horas\n",
      "Una vez hace ya muchas décadas dijo T.S. Eliot que \"no debemos dejar de explorar, y al final de nuestras exploraciones llegaremos al lugar del que partimos, y lo conoceremos por primera vez\". Y es que sin estudiar ni comprender lo que nos rodea nunca llegaremos a saber quiénes somos en realidad. Sea cual sea el coste a pagar el ser humano tiene el don y la capacidad (por lo tanto la obligación) de superar sus fronteras y despegar sus pies del suelo. Estamos destinados a ello. Nuestro futuro está en las estrellas.\n",
      "29/09/2014 11:34 horas\n",
      "Cuánta razón tiene!!! Desechar la curiosidad de explorar lo inaudito supone la hazaña de la mediocridad del hombre. Gracias Walt desde España. La nacionalidad es lo de menos.\n",
      "29/09/2014 08:58 horas\n",
      "No creo que haya que preocuparse mucho, los viajes de exploración humanos siempre han venido motivados por el comercio, el día que en la Luna o en Marte se encuentren recursos explotables ya veremos a los humanos volar como langostas a destripar esos mundos.\n",
      "29/09/2014 06:45 horas\n",
      "El carácter militar de la carrera espacial hacía normal el riesgo de perder vidas. Hoy en día esto ha cambiado, se parece mucho más a una aventura comercial. Tienen que cambiar mucho las cosas aquí abajo para que se relance la exploración espacial pionera. Será real cuando solucionemos las \"pequeñas\" diferencias que provocan que el mundo no conozca un sólo día de paz. \n",
      "\n",
      "Grupo 3 | Quienes Somos\n",
      "Estamos formados por un grupo de profesionales especializados en diseño y desarrollo de arquitectura bioclimática e ingeniería sostenible.\n",
      "Contamos con mas de 15 años de experiencia en Quintana Roo avalados por diversos proyectos a lo largo del estado, desde Cancún hasta Chetumal, con base de operaciones en Playa del Carmen. Nuestra amplia experiencia nos permite el correcto y óptimo desarrollo de proyectos desde su fase inicial de planificación, diseño y proyecto ejecutivo, utilizando plataforma BIM, hasta su construcción y habilitación con un minucioso estudio de costos, tiempos y desempeño, lo cual implica un perfecto balance costo-beneficio para nuestros clientes mas exigentes.\n",
      "Brindar soluciones profesionales y eficientes para Proyectos y Construcción, optimizando la relación costo-beneficio para nuestros clientes y el impacto al medio ambiente, contribuyendo de esta manera a un desarrollo responsable.\n",
      "Ser una empresa influyente en el progreso y desarrollo inmobiliario de la región, como así también en el mantenimiento y mejoras a la infraestructura, aplicando tecnología vanguardista y amigable con el medio ambiente, minimizando al máximo el impacto negativos al mismo. \n",
      "\n",
      "CaniSport:,noticias mundo deportivo,nutricion,proteinas,ejercicios dietas: ¿Qué es la Hipertensión Pulmonar?\n",
      "En esta oportunidad hablaremos sobre una enfermedad poco frecuente pero es realmente muy seria, hablaremos sobre la hipertensión pulmonar.\n",
      "La hipertensión pulmonar es un extraño padecimiento en el que la presión de las arterias que conectan a los pulmones con el corazón se eleva sobre los niveles normales.\n",
      "Esta condición le exige al corazón trabajar de manera forzada y con bajos niveles de oxígeno en la sangre, provocando fatiga y dificultad para respirar.\n",
      "El gran problema es que los síntomas de la hipertensión pulmonar pueden confundirse con los de asma, anemia y patología de tiroides, que son más comunes entre la población.\n",
      "El doctor Alberto Matsuno, neumólogo explicó: \"La hipertensión pulmonar no es una enfermedad muy frecuente, pero si es devastadora porque si los pacientes no reciben tratamiento su expectativa de vida no es más de tres años\".\n",
      "Se estima que la prevalencia de la hipertensión pulmonar en el mundo es de 30 a 50 casos por millón; y como ocurre con la mayoría de enfermedades crónicas, su diagnóstico y tratamiento temprano evitan, o demoran, el deterioro de la calidad de vida del paciente.\n",
      "Así mismo el doctor Alberto Matsuno mencionó que \"Las causas son múltiples, hay causas propias pulmonares, cardiológicas, hereditarias y causas por enfermedades del colágeno, es decir, esclerosis o esclerodermia que es una de las causas frecuentes\".\n",
      "Aunque no existe una explicación científica del por qué esta enfermedad es más común en mujeres que en hombres, los nuevos tratamientos y cuidados especializados han mejorado, significativamente, el pronóstico de vida.\n",
      "Asímismo el galeno indicó que si estos pacientes no responden a este esquema de tratamiento, deberán someterse a un trasplante pulmonar. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data[i]['text'], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdeab6",
   "metadata": {},
   "source": [
    "Podemos ver que hay algunos textos con erratas, y con lenguas de hispanoamérica, lo cual puede ser interesante para ver el desempeño del etiquetado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ac5ca",
   "metadata": {},
   "source": [
    "## 3.3 Almacenar datos\n",
    "Ahora vamos a guardar los datos en un archivo y en el siguiente notebook sacaremos las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"CulturaX\"\n",
    "with open(filename, \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(data)\n",
    "print(f\"Archivo guardado correctamente como {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a78e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
